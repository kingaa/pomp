\documentclass[article,pdftex,shortnames,nojss]{jss}
%\VignetteEngine{knitr::knitr}
\usepackage{paralist,amsmath,amssymb,thumbpdf,lmodern}
\graphicspath{{figure/}}
\shortcites{Blake2014,Kendall1999,Kendall2005,pomp}

\usepackage{enumerate,alltt}
\usepackage[ruled,noline,linesnumbered]{algorithm2e}
\SetKwFor{For}{for}{do}{end}
\SetKwFor{While}{while}{do}{end}
\SetKwInput{KwIn}{input}
\SetKwInput{KwOut}{output}
\SetKwInput{KwCplx}{complexity}
\SetKwBlock{Begin}{procedure}{}
\DontPrintSemicolon

\newcommand\featureFunc{\mathbb{S}}
\newcommand\loglik{\ell}
\newcommand\loglikMC{\hat\ell}
\newcommand\synloglik{\loglik_{\featureFunc}}
\newcommand\synloglikMC{\loglikMC_{\featureFunc}}
\newcommand\R{\mathbb{R}}
\newcommand\slot[1]{\code{#1}}
\newcommand\class[1]{`\code{#1}'}
\newcommand\prob[1]{\mathbb{P}\left[{#1}\right]}
\def\dd{\mathrm{d}}
\newcommand\given{{\,\vert\,}}
\newcommand\equals{{{\,}={\,}}}
\newcommand\myequals{\hspace{0.5mm}{=}\hspace{0.5mm}}
\newcommand\seq[2]{{#1}\!:\!{#2}}
\newcommand\mydot{{\,\cdot\,}}
\newcommand\cp[2]{N_{\mathrm{#1}\mathrm{#2}}}
\newcommand\BirthDeath{\raisebox{-0.3ex}{\scalebox{1.5}{$\cdot$}}}
\newcommand\giventh{{\hspace{0.5mm};\hspace{0.5mm}}}
\newcommand\normal{{\mathrm{Normal}}}
\newcommand\argequals{{\,=\,}}
\newcommand\lags{c}
\newcommand\maxlag{\overline{c}}
\newcommand\nlfList{C}
\newcommand\bigO[1]{\mathcal{O}\!\left({#1}\right)}
\newcommand\dimtheta{d}
\newcommand\DimTheta{D}
\newcommand\DimX{\mathrm{dim}(X)}
\newcommand\DimY{\mathrm{dim}(Y)}
\newcommand\nprobe{q}
\newcommand\Nprobe{Q}
\newcommand\carryingCapacity{K}

\usepackage[sort&compress]{cleveref}
\newcommand{\crefrangeconjunction}{--}
\crefname{figure}{Figure}{Figures}
\Crefname{figure}{Figure}{Figures}
\crefname{table}{Table}{Tables}
\Crefname{table}{Table}{Tables}
\crefname{equation}{Equation}{Equations}
\Crefname{equation}{Equation}{Equations}
\creflabelformat{equation}{#2#1#3}
\crefname{appendix}{Appendix}{Appendices}
\Crefname{appendix}{Appendix}{Appendices}
\crefname{algorithm}{Algorithm}{Algorithms}
\Crefname{algorithm}{Algorithm}{Algorithms}
\crefname{section}{Section}{Sections}
\Crefname{section}{Section}{Sections}
\crefname{AlgoLine}{line}{lines}
\Crefname{AlgoLine}{Line}{Lines}

\author{Aaron A. King\\University of Michigan \And
  Dao Nguyen\\University of Mississippi \And
  Edward L. Ionides\\University of Michigan}
\Plainauthor{Aaron A. King, Dao Nguyen, Edward L. Ionides}

\title{Statistical Inference for Partially Observed Markov Processes via the \proglang{R} Package \pkg{pomp}}
\Plaintitle{Statistical Inference for Partially Observed Markov Processes via the R Package pomp}
\Shorttitle{\pkg{pomp}: Partially Observed Markov Processes in \proglang{R}}

\Abstract{
  Partially observed Markov process (POMP) models, also known as hidden Markov models or state space models, are ubiquitous tools for time series analysis.
  The \proglang{R} package \pkg{pomp} provides a very flexible framework for Monte~Carlo statistical investigations using nonlinear, non-Gaussian POMP models.
  A range of modern statistical methods for POMP models have been implemented in this framework including sequential Monte~Carlo, iterated filtering, particle Markov chain Monte~Carlo, approximate Bayesian computation, maximum synthetic likelihood estimation, nonlinear forecasting, and trajectory matching.
  In this paper, we demonstrate  the application of these methodologies using some simple toy problems.
  We also illustrate the specification of more complex POMP models, using a nonlinear epidemiological model with a discrete population, seasonality, and extra-demographic stochasticity.
  We discuss the specification of user-defined models and the development of additional methods within the programming environment provided by \pkg{pomp}.

  \noindent
  *This document is an updated version of \href{https://dx.doi.org/10.18637/jss.v069.i12}{\emph{Journal of Statistical Software} \textbf{69}(12): 1--43}.
  It has been revised substantially to reflect changes in \pkg{pomp} subsequent to the original publication.
  It is provided under the \href{https://creativecommons.org/licenses/by/3.0/}{Creative Commons Attribution License}.
}

\Keywords{Markov processes, hidden Markov model, state space model, stochastic dynamical system, maximum likelihood, plug-and-play, time series, mechanistic model, sequential Monte Carlo, \proglang{R}}
\Plainkeywords{Markov processes, hidden Markov model, state space model, stochastic dynamical system, maximum likelihood, plug-and-play, time series, mechanistic model, sequential Monte Carlo, R}

\Address{
  Aaron A. King\\
  Departments of Ecology \& Evolutionary Biology and Mathematics\\
  Center for the Study of Complex Systems\\
  University of Michigan\\
  Ann Arbor, MI 48109, United States of America\\
  E-mail: \email{kingaa@umich.edu}\\
  URL: \url{https://kinglab.eeb.lsa.umich.edu/}\\

  Dao Nguyen\\
  Department of Mathematics\\
  University of Mississippi\\
  University, MI 38677, United States of America\\
  E-mail: \email{dxnguyen@olemiss.edu}\\

  Edward Ionides\\
  Department of Statistics\\
  University of Michigan\\
  Ann Arbor, MI 48109, United States of America\\
  E-mail: \email{ionides@umich.edu}\\
  URL: \url{https://www.stat.lsa.umich.edu/~ionides/}\\

}

<<packages,include=FALSE,cache=FALSE>>=
library("pomp")
library("coda")
library("foreach")
library("doParallel")
library("tidyverse")
library("grid")
library("xtable")

stopifnot(packageVersion("pomp")>="4.5.1")

<<set-opts,include=FALSE,cache=FALSE>>=
options(
  scipen=2,
  help_type="html",
  pomp_archive_dir="results/pompjss",
  stringsAsFactors=FALSE,
  prompt="R> ",
  continue="+  ",
  width=60,
  formatR.blank=FALSE,
  formatR.indent=2,
  useFancyQuotes=FALSE,
  xtable.comment=FALSE
)
@

<<knitr-opts,include=FALSE,cache=FALSE,purl=FALSE>>=
library("knitr")
opts_knit$set(concordance=TRUE)
opts_chunk$set(
             progress=TRUE,prompt=TRUE,highlight=FALSE,
             tidy=TRUE,
             comment="",
             warning=FALSE,
             message=FALSE,
             error=TRUE,
             echo=TRUE,
             strip.white=TRUE,
             results="markup",
             background="#FFFFFF00",
             size="normalsize",
             fig.path="tmp/pompjss/figure/",
             cache.path="tmp/pompjss/cache/",
             fig.lp="fig:",
             fig.align="left",
             fig.show="asis",
             fig.height=5,fig.width=8,
             out.width="\\textwidth",
             dpi=300,
             dev="png",
             dev.args=list(
               bg="transparent",
               pointsize=12
             )
           )

<<set-seed,cache=FALSE,include=FALSE>>=
set.seed(5384959L)
@

<<timing1,echo=FALSE,cache=FALSE>>=
bigtick <- Sys.time()
@

\begin{document}

\section {Introduction}

A partially observed Markov process (POMP) model consists of incomplete and noisy measurements of a latent, unobserved Markov process.
The far-reaching applicability of this class of models has motivated much software development \citep{Commandeur2011}.
It has been a challenge to provide a software environment that can effectively handle broad classes of POMP models and take advantage of the wide range of statistical methodologies that have been proposed for such models.
The \pkg{pomp} software package \citep{pomp} differs from previous approaches by providing a general and abstract representation of a POMP model.
Therefore, algorithms implemented within \pkg{pomp} are necessarily applicable to arbitrary POMP models.
Moreover, models formulated with \pkg{pomp} can be analyzed using multiple methodologies in search of the most effective method, or combination of methods, for the problem at hand.
However, since  \pkg{pomp} is designed for general POMP models, methods that exploit additional model structure have yet to be implemented.
In particular, when linear, Gaussian approximations are adequate for one's purposes, or when the latent process takes values in a small, discrete set, methods that exploit these additional assumptions to advantage, such as the extended and ensemble Kalman filter methods or exact hidden Markov model methods, are available, but not yet as part of \pkg{pomp}.
It is the class of nonlinear, non-Gaussian POMP models with large state spaces upon which \pkg{pomp} is focused.

A POMP model may be characterized by the transition density for the Markov process and the measurement density\footnote{We use the term ``density'' in this article to encompass both the continuous and discrete cases.
  Thus, in the latter case, i.e., when state variables and/or measured quantities are discrete, one could replace ``probability density function'' with ``probability mass function''.}.
However, some methods require only simulation from the transition density whereas others require evaluation of this density.
Still other methods may not work with the model itself but with an approximation, such as a linearization.
Algorithms for which the dynamic model is specified only via a simulator are said to be {\it plug-and-play} \citep{Breto2009,He2010}.
Plug-and-play methods can be employed once one has ``plugged'' a model simulator into the inference machinery.
Since many POMP models of scientific interest are relatively easy to simulate, the plug-and-play property facilitates data analysis.
Even if one candidate model has tractable transition probabilities, a scientist will frequently wish to consider alternative models for which these probabilities are intractable.
In a plug-and-play methodological environment, analysis of variations in the model can often be achieved by changing a few lines of the model simulator codes.
The price one pays for the flexibility of plug-and-play methodology is primarily additional computational effort, which can be substantial.
Nevertheless, plug-and-play methods implemented using \pkg{pomp} have proved capable for state-of-the-art inference problems \citep[e.g.,][]{King2008,Bhadra2011,Shrestha2011,Shrestha2013,Earn2012,Roy2013,Blackwood2013,Blackwood2013b,He2013a,Breto2014,Blake2014}.
The recent surge of interest in plug-and-play methodology for POMP models includes the development of
nonlinear forecasting \citep{Ellner1998},
iterated filtering \citep{Ionides2006,Ionides2015},
ensemble Kalman filtering \citep{Shaman2012},
approximate Bayesian computation \citep[ABC;][]{Sisson2007},
particle Markov chain Monte~Carlo \citep[PMCMC;][]{Andrieu2010},
probe matching \citep{Kendall1999},
and
synthetic likelihood \citep{Wood2010}.
Although the \pkg{pomp} package provides a general environment for methods with and without the plug-and-play property, development of the package to date has emphasized plug-and-play methods.

The \pkg{pomp} package is philosophically neutral as to the merits of Bayesian inference.
It enables a POMP model to be supplemented with prior distributions on parameters, and several Bayesian methods are implemented within the package.
Thus \pkg{pomp} is a convenient environment for those who wish to explore both Bayesian and non-Bayesian data analyses.

The remainder of this paper is organized as follows.
\Cref{sec:background} defines mathematical notation for POMP models and relates this to their representation as objects of class \class{pomp} in the \pkg{pomp} package.
\Cref{sec:methods} introduces several of the statistical methods currently implemented in \pkg{pomp}.
\Cref{sec:examples} constructs and explores a simple POMP model, demonstrating the use of the available statistical methods.
\Cref{sec:EpidemicModel} illustrates the implementation of more complex POMPs, using a model of infectious disease transmission as an example.
Finally, \cref{sec:conclusion} discusses extensions and applications of \pkg{pomp}.


\section[POMP models and their representation in pomp]{POMP models and their representation in \pkg{pomp}}
\label{sec:background}

Let $\theta$ be a $\DimTheta$-dimensional real-valued parameter, $\theta\in\R^{\DimTheta}$.
For each value of $\theta$, let $\{X(t\giventh\theta),t\in T\}$ be a Markov process,
with $X(t\giventh\theta)$ taking values in $\R^{\DimX}$.
The time index set $T\subset\mathbb{R}$ may be an interval or a discrete set.
Let $\{t_i\in T, i=1,\dots,N\}$, be the times at which $X(t\giventh\theta)$ is observed, and $t_{0}\in T$ be an initial time.
Assume $t_{0}\le t_{1}<t_{2}<\cdots<t_{N}$.
We write $X_i=X(t_i\giventh\theta)$ and $X_{i:j}=(X_{i},\ X_{i+1},\dots,X_{j})$.
The process $X_{0:N}$ is only observed by way of another process $Y_{1:N}=(Y_1,\dots,Y_N)$ with $Y_n$ taking values in  $\R^{\DimY}$.
The observable random variables $Y_{1:N}$ are assumed to be conditionally independent given $X_{0:N}$.
The data, $y_{1:N}^{*}=(y_{1}^{*},\ \ldots,\ y_{N}^{*})$, are modeled as a realization of this observation process and are considered fixed.
We suppose that $X_{0:N}$ and $Y_{1:N}$ have a joint density $f_{X_{0:N},Y_{1:N}}(x_{0:N},\ y_{1:N}\giventh\theta)$.
The POMP structure implies that this joint density is determined by the initial density, $f_{X_{0}}(x_{0};\theta)$, together with the conditional transition probability density, $f_{X_{n}|X_{n-1}}(x_{n}\given x_{n-1}\giventh\theta)$, and the measurement density, $f_{Y_{n}|X_{n}}(y_{n}\given x_{n}\giventh\theta)$, for $1\leq n\leq N$.
In particular, we have
\begin{equation}\label{eq:joint-dens}
  f_{X_{0:N},Y_{1:N}}(x_{0:N},y_{1:N};\theta) = f_{X_0}(x_0;\theta)\,\prod_{n=1}^N\!f_{X_n | X_{n-1}}(x_n|x_{n-1};\theta)\,f_{Y_n|X_n}(y_n|x_n;\theta).
\end{equation}
Note that this formalism allows the transition density, $f_{X_{n}|X_{n-1}}$, and measurement density, $f_{Y_{n}|X_{n}}$, to depend explicitly on $n$.


\subsection{Implementation of POMP models}
\label{sec:implementation}

\pkg{pomp} is fully object-oriented:
in the package, a POMP model is represented by an \proglang{S}4 object \citep{Chambers1998,Genolini2008} of class \class{pomp}.
Slots in this object encode the components of the POMP model, and can be filled or changed using the constructor function \code{pomp} and various other convenience functions.
Methods for the \class{pomp} class use these components to carry out computations on the model.
\Cref{tab:notation} gives the mathematical notation corresponding to the elementary methods that can be executed on a class-\class{pomp} object.

\begin{table}[t!]
  \begin{center}
    \begin{tabular}{llll}
      \hline
      Method &Argument to the &Mathematical terminology \\
      & \code{pomp} constructor & \\
      \hline
      \code{rprocess} &\code{rprocess} &Simulate from $f_{X_n|X_{n-1}}( x_n \given x_{n-1}\giventh \theta)$\\
      \code{dprocess} &\code{dprocess} &Evaluate $f_{X_n|X_{n-1}}( x_n \given x_{n-1}\giventh \theta)$\\
      \code{rmeasure} &\code{rmeasure} &Simulate from $f_{Y_n|X_n}( y_n \given x_n\giventh \theta)$\\
      \code{dmeasure} &\code{dmeasure} &Evaluate $f_{Y_n|X_n}( y_n \given x_n\giventh \theta)$\\
      \code{rprior} &\code{rprior} &Simulate from the prior distribution $\pi(\theta)$\\
      \code{dprior} &\code{dprior} &Evaluate the prior density $\pi(\theta)$\\
      \code{rinit} &\code{rinit} &Simulate from $f_{X_0}( x_0 \giventh \theta)$\\
      \code{timezero} &\code{t0} &$t_0$\\
      \code{time} &\code{times} &$t_{1:N}$\\
      \code{obs} &\code{data} &$y^*_{1:N}$\\
      \code{states} & --- &$x_{0:N}$\\
      \code{coef} &\code{params} &$\theta$\\
      \hline
    \end{tabular}
  \end{center}
  \caption{
    Constituent methods for class-\class{pomp} objects and their translation into mathematical notation for POMP models.
    For example, the \code{rprocess} method is set using the \code{rprocess} argument to the \code{pomp} constructor function.
    \label{tab:notation}
  }
\end{table}

The \code{rprocess}, \code{dprocess}, \code{rmeasure}, and \code{dmeasure} arguments specify the transition probabilities $f_{X_n|X_{n-1}}( x_n \given x_{n-1}\giventh \theta)$ and measurement densities $f_{Y_n|X_n}(y_n\given x_n\giventh \theta)$.
Not all of these arguments must be supplied for any specific computation.
In particular, plug-and-play methodology by definition never uses \code{dprocess}.
An empty \slot{dprocess} slot in a class-\class{pomp} object is therefore acceptable unless a non-plug-and-play algorithm is attempted.
In the package, the data and corresponding measurement times are considered necessary parts of a class-\class{pomp} object whilst specific values of the parameters and latent states are not.
%% It is nevertheless useful to have slots for parameters and states as these are natural properties of a simulation from a POMP model.
Applying the \code{simulate} function to an object of class \class{pomp} returns another class-\class{pomp} object, within which the data $y^*_{1:N}$ have been replaced by a stochastic realization of $Y_{1:N}$, the corresponding realization of $X_{0:N}$ is accessible via the \code{states} method, and the \code{params} slot has been filled with the value of $\theta$ used in the simulation.

To illustrate the specification of models in \pkg{pomp} and the use of the package's inference algorithms, we will use a simple example.
The \citet{Gompertz1825} model can be constructed via
<<eval=FALSE,purl=FALSE>>=
library("pomp")
gomp <- gompertz()
@
which results in the creation of a class-\class{pomp} object, named \code{gompertz}, in the workspace.
The structure of this model and its implementation in \pkg{pomp} is described below, in \cref{sec:examples}.
One can view the components of \code{gompertz} listed in \cref{tab:notation} by executing
<<eval=FALSE,purl=FALSE>>=
obs(gomp)
states(gomp)
as.data.frame(gomp)
plot(gomp)
timezero(gomp)
time(gomp)
coef(gomp)
@

\subsection{Initial conditions}

In some experimental situations, $f_{X_0}(x_0\giventh\theta)$ corresponds to a known experimental initialization, but in general the initial state of the latent process will have to be inferred.
If the transition density for the dynamic model, $f_{X_n|X_{n-1}}(x_n\given x_{n-1}\giventh \theta)$, does not depend on time and possesses a unique stationary distribution, it may be natural to set $f_{X_0}(x_0\giventh\theta)$ to be this stationary distribution.
Otherwise, and more commonly in the authors' experience, no clear scientifically motivated choice of $f_{X_0}(x_0\giventh\theta)$ exists and one can proceed by treating the value of $X_0$ as a parameter to be estimated.
In this case, $f_{X_0}(x_0\giventh\theta)$ concentrates at a point, the location of which depends on $\theta$.

\subsection{Covariates}

Scientifically, one may be interested in the role of a vector-valued covariate process $\{Z(t)\}$ in explaining the data.
Modeling and inference conditional on $\{Z(t)\}$ can be carried out within the general framework for nonhomogeneous POMP models, since the arbitrary densities $f_{X_n|X_{n-1}}$, $f_{X_0}$ and $f_{Y_n|X_n}$ can depend on the observed process $\{Z(t)\}$.
For example, it may be the case that $f_{X_n|X_{n-1}}(x_n\given x_{n-1}\giventh\theta)$ depends on $n$ only through $Z(t)$ for $t_{n-1}\le t\le t_{n}$.
The \code{covariate\_table} argument in the \pkg{pomp} constructor allows for time-varying covariates measured at arbitrary times.
An example using covariates is given in \cref{sec:EpidemicModel}.

\section{Methodology for POMP models}
\label{sec:methods}

Data analysis typically involves identifying regions of parameter space within which a postulated model is statistically consistent with the data.
Additionally, one frequently desires to assess the relative merits of alternative models as explanations of the data.
Once the user has encoded one or more POMP models as class-\class{pomp} objects, the package provides a variety of algorithms to assist with these data analysis goals.
\Cref{tab:methods} provides an overview of several inference methodologies for POMP models.
Each method may be categorized as full-information or feature-based, Bayesian or frequentist, and plug-and-play or not plug-and-play.

Approaches that work with the full likelihood function, whether in a Bayesian or frequentist context, can be called full-information methods.
Since low-dimensional sufficient statistics are not generally available for POMP models, methods which take advantage of favorable low-dimensional representations of the data typically lose some statistical efficiency.
We use the term ``feature-based'' to describe all methods not based on the full likelihood, since such methods statistically emphasize some features of the data over others.

Many Monte Carlo methods of inference can be viewed as algorithms for the exploration of high-dimensional surfaces.
This view obtains whether the surface in question is the likelihood surface or that of some other objective function.
The premise behind many recent methodological developments in Monte Carlo methods for POMP models is that generic stochastic numerical analysis tools, such as standard Markov chain Monte Carlo and Robbins-Monro type methods, are effective only on the simplest models.
For many models of scientific interest, therefore, methods that leverage the POMP structure are needed.
Though \pkg{pomp} has sufficient flexibility to encode arbitrary POMP models and methods and therefore also provides a platform for the development of novel POMP inference methodology,
\pkg{pomp}'s development to date has focused on plug-and-play methods.
However, the package developers welcome contributions and collaborations to further expand \pkg{pomp}'s functionality in non-plug-and-play directions also.
In the remainder of this section, we describe and discuss several inference methods, all currently implemented in the package.

\begin{table}[t!]
  \begin{tabular}{lp{0.35\linewidth}p{0.35\linewidth}}
    \multicolumn{3}{l}{\em (a) Plug-and-play \rule[-2mm]{0mm}{4mm}  }\tabularnewline
    \hline
    &Frequentist   & Bayesian  \tabularnewline
    \hline
    Full information&
    Iterated filtering (\code{mif2}, \cref{sec:mif}) \raggedright
    &PMCMC (\code{pmcmc}, \cref{sec:pmcmc}) \raggedright \tabularnewline
    \hline
    Feature-based
    &Nonlinear forecasting (\code{nlf}, \cref{sec:nlf}), \raggedright
    &ABC (\code{abc}, \cref{sec:abc}) \raggedright \tabularnewline
    &synthetic likelihood (\code{probe\_objfun}, \cref{sec:probe}) \raggedright
    & \tabularnewline
    \hline
    \multicolumn{3}{c}{}\tabularnewline
    \multicolumn{3}{l}{\em (b) Not plug-and-play \rule[-2mm]{0mm}{4mm}} \tabularnewline
    \hline
    & Frequentist         & Bayesian  \tabularnewline
    \hline
    Full information
    & EM and Monte~Carlo~EM,  \raggedright
    & MCMC \raggedright \tabularnewline
    & Kalman filter \raggedright
    & \tabularnewline
    \hline
    Feature-based
    &Trajectory matching (\code{traj\_objfun}),  \raggedright
    & Extended Kalman filter \tabularnewline
    &extended Kalman filter,  \raggedright
    & \tabularnewline
    &Yule-Walker equations  \raggedright
    & \tabularnewline
    \hline
  \end{tabular}
  \caption{
    Inference methods for POMP models.
    For those currently implemented in \pkg{pomp}, the function name and a reference for description are provided in parentheses.
    Standard expectation-maximization (EM) and Markov chain Monte~Carlo (MCMC) algorithms are not plug-and-play since they require evaluation of $f_{X_n|X_{n-1}}(x_n\given x_{n-1}\giventh\theta)$.
    The Kalman filter and extended Kalman filter are not plug-and-play since they cannot be implemented based on a model simulator.
    The Kalman filter provides the likelihood for a linear, Gaussian model.
    The extended Kalman filter employs a local linear Gaussian approximation which can be used for frequentist inference (via maximization of the resulting quasi-likelihood) or approximate Bayesian inference (by adding the parameters to the state vector).
    The Yule-Walker equations for ARMA models provide an example of a closed-form method of moments estimator.
  }
  \label{tab:methods}
\end{table}

\subsection{The likelihood function and sequential Monte Carlo}
\label{sec:pfilter}

%%%%  PFILTER PSEUDOCODE
\begin{algorithm}[t!]
  \caption{\textbf{Sequential Monte Carlo (SMC, or particle filter)}:
    \code{pfilter(\,P,\,Np{\argequals}$J$)}, using notation from \cref{tab:notation} where \code{P} is a class-\class{pomp} object with definitions for \code{rprocess}, \code{dmeasure}, \code{rinit}, \code{coef}, and \code{obs}.
    \label{alg:pfilter}
  }
  \KwIn{
    Simulator for $f_{X_n|X_{n-1}}(x_n\given x_{n-1}\giventh\theta)$;
    evaluator for $f_{Y_n|X_n}(y_n\given x_{n}\giventh\theta)$;
    simulator for $f_{X_0}(x_0\giventh\theta)$;
    parameter, $\theta$;
    data, $y^*_{1:N}$;
    number of particles, $J$.
  }
  \BlankLine
  Initialize filter particles:
  simulate ${X}_{0,j}^{F}\sim {f}_{{X}_{0}}\left(\mydot\giventh{\theta}\right)$ for $j$ in $\seq{1}{J}$.\;
  \For{$n$ in $\seq{1}{N}$}{
    Simulate for prediction:
    ${X}_{n,j}^{P}\sim {f}_{{X}_{n}|{X}_{n-1}}\big(\mydot|{X}_{n-1,j}^{F};{\theta}\big)$ for $j\ \text{in}\ \seq{1}{J}$. \nllabel{alg:pfilter:step1}\;
    Evaluate weights:
    $w(n,j)={f}_{{Y}_{n}|{X}_{n}}(y_{n}^{*}|{X}_{n,j}^{P}\giventh{\theta})$ for $j$ in $\seq{1}{J}$.\;
    Normalize weights:
    $\tilde{w}(n,j)= w(n,j)/\sum_{m=1}^{J}w(n,m)$.\;
    Apply \cref{alg:systematic} to select indices $k_{1:J}$ with $\prob{k_{j}=m} =\tilde{w}(n,m)$.\nllabel{alg:pfilter:systematic}\;
    Resample:
    set ${X}_{n,j}^{F}={X}_{n,k_{j}}^{P}$ for $j$ in $\seq{1}{J}$. \nllabel{alg:pfilter:step2} \;
    Compute conditional log likelihood: $\loglikMC_{n|1:n-1}=\log\big(J^{-1}\,\sum_{m=1}^{J}\!w(n,m)\big)$.\;
  }
  \KwOut{
    Log likelihood estimate, $\loglikMC(\theta)=\sum_{n=1}^N\loglikMC_{n|1:n-1}$;
    filter sample, $X^F_{n,1:J}$, for $n$ in $\seq{1}{N}$.
  }
  \KwCplx{$\bigO{J}$}
\end{algorithm}

The log likelihood for a POMP model is $\loglik(\theta)=\log{f_{Y_{1:N}}(y^*_{1:N}\giventh\theta)}$, which can be written as a sum of conditional log likelihoods,
\begin{equation}\label{eq:loglik:factorization}
  \loglik(\theta)=\sum_{n=1}^N\!\loglik_{n|1:n-1}(\theta),
\end{equation}
where
\begin{equation}
  \loglik_{n|1:n-1}(\theta)=\log f_{Y_n|Y_{1:n-1}}(y^*_n\given y^*_{1:n-1}\giventh\theta),
\end{equation}
and we use the convention that $y^*_{1:0}$ is an empty vector.
The structure of a POMP model implies the representation
\begin{equation}\label{eq:condLoglik}
  \loglik_{n|1:n-1}(\theta)=\log\int \!
  f_{Y_{n}|X_{n}}(y_{n}^{*}|x_{n}\giventh\theta) f_{X_n|Y_{1:n-1}}(x_n\given y^*_{1:n-1}\giventh\theta)\,
  dx_{n}
\end{equation}
(cf.~\cref{eq:joint-dens}).
Although $\loglik(\theta)$ typically has no closed form, it can frequently be computed by Monte Carlo methods.
Sequential Monte Carlo (SMC) builds up a representation of $f_{X_n|Y_{1:n-1}}(x_n\given y^*_{1:n-1}\giventh\theta)$ that can be used to obtain an estimate, $\loglikMC_{n|1:n-1}(\theta)$, of $\loglik_{n|1:n-1}(\theta)$ and hence an approximation, $\loglikMC(\theta)$, to $\loglik(\theta)$.
SMC (a basic version of which is presented as \cref{alg:pfilter}), is also known as the particle filter, since it is conventional to describe the Monte Carlo sample, $\{X^F_{n,j},j\ \text{in}\ \seq{1}{J}\}$ as a swarm of particles representing $f_{X_n|Y_{1:n}}(x_n\given y^*_{1:n}\giventh\theta)$.
The swarm is propagated forward according to the dynamic model and then assimilated to the next data point.
Using an evolutionary analogy, the prediction step (\cref{alg:pfilter:step1}) mutates the particles in the swarm and the filtering step (\cref{alg:pfilter:step2}) corresponds to selection.
SMC is implemented in \pkg{pomp} in the \code{pfilter} function.
The basic particle filter in \cref{alg:pfilter} possesses the plug-and-play property.
Many variations and elaborations to SMC have been proposed;
these may improve numerical performance in appropriate situations \citep{Cappe2007} but typically lose the plug-and-play property.
\citet{Arulampalam2002}, \citet{Doucet2009}, and \citet{Kantas2015} have written excellent introductory tutorials on the particle filter and particle methods more generally.

Basic SMC methods fail when an observation is extremely unlikely given the model.
This leads to the situation that at most a few particles are consistent with the observation, in which case the effective sample size \citep{Liu2001a} of the Monte Carlo sample is small and the particle filter is said to suffer from \emph{particle depletion}.
Many elaborations of the basic SMC algorithm have been proposed to ameliorate this problem.
However, it is often preferable to remedy the situation by seeking a better model.
The plug-and-play property assists in this process by facilitating investigation of alternative models.

%%%% SYSTEMATIC SAMPLING PSEUDOCODE
\begin{algorithm}[t!]
  \caption{
    \textbf{Systematic resampling}:
    \Cref{alg:pfilter:systematic} of \cref{alg:pfilter}.
    \label{alg:systematic}
  }
  \KwIn{
    Weights, $\tilde{w}_{1:J}$, normalized so that $\sum_{j=1}^J \tilde{w}_j=1$.
  }
  \BlankLine
  Construct cumulative sum:
  $c_j=\sum_{m=1}^j \tilde{w}_m$, for $j$ in $1:J$.\;
  Draw a uniform initial sampling point:
  $U_1\sim\mathrm{Uniform}(0,J^{-1})$.\;
  Construct evenly spaced sampling points:
  $U_j=U_1 + (j-1)J^{-1}$, for $j\ \text{in}\ 2:J$.\;
  Initialize: set $p=1$.\;
  \For {$j\ \text{in}\ 1:J$}{
    \While {$U_j>c_p$}{
      Step to the next resampling index:
      set $p=p+1$.\;
    }
    Assign resampling index:
    set $k_j=p$.\;
  }
  \KwOut{Resampling indices, $k_{1:J}$.}
  \KwCplx{$\bigO{J}$}
\end{algorithm}

In \cref{alg:pfilter:systematic} of \cref{alg:pfilter}, systematic resampling (\cref{alg:systematic}) is used in preference to multinomial resampling.
\Cref{alg:systematic} reduces Monte~Carlo variability while resampling with the proper marginal probability.
In particular, if all the particle weights are equal then \cref{alg:systematic} has the appropriate behavior of leaving the particles unchanged.
As pointed out by \citet{Douc2005}, stratified resampling performs better than multinomial sampling and \cref{alg:systematic} is in practice comparable in performance to stratified resampling and somewhat faster.

%%% ITERATED FILTERING
\subsection{Iterated filtering}
\label{sec:mif}

% MIF PSEUDOCODE
\begin{algorithm}[t!]
  \caption{
    \textbf{Iterated filtering}:
    \texttt{mif2(P, params{\argequals}$\theta_0$, Nmif{\argequals}$M$, Np{\argequals}$J$, rw.sd{\argequals} $\sigma_{0:N,1:\DimTheta}$, cooling.fraction.50{\argequals}$a$)},
    using notation from \cref{tab:notation}
    where \code{P} is a class-\class{pomp} object with defined \code{rprocess}, \code{dmeasure}, \code{rinit}, and \code{obs} components.
    \label{alg:mif}
  }
  \KwIn{
    Simulators for $f_{X_0}(x_0;\theta)$ and $f_{X_n|X_{n-1}}(x_n| x_{n-1}; \theta)$;
    evaluator for $f_{Y_n|X_n}(y_n| x_n;\theta)$;
    data, $y^*_{1:N}$;
    Number of iterations, $M$;
    number of particles, $J$;
    initial parameter swarm, $\{\Theta^0_j, j=1,\dots,J\}$;
    random walk intensity, a $\DimTheta\times\DimTheta$ diagonal matrix $V_n$ with entries $\sigma^2_{n,\dimtheta}$;
    cooling fraction in 50 iterations, $a$.
  }
  \BlankLine
  \For {$m$ in $1{:} M$}{
    $\Theta^{F,m}_{0,j}\sim \normal\big(\Theta^{m-1}_{j},V_0 \, a^{2m/50}\big)$ for $j$ in $1{:} J$\label{alg:mif:init:perturb}\;
    $X_{0,j}^{F,m}\sim f_{X_0}(x_0 ; \Theta^{F,m}_{0,j})$ for $j$ in $1{:} J$\;
    \For {$n$ in $1{:} N$}{
      $\Theta^{P,m}_{n,j}\sim \normal\big(\Theta^{F,m}_{n-1,j},V_n \, a^{2m/50}\big)$ for $j$ in $1{:} J$\label{alg:mif:perturb}\;
      $X_{n,j}^{P,m}\sim f_{X_n|X_{n-1}}(x_n | X^{F,m}_{n-1,j}; \Theta^{P,m}_{n,j})$ for $j$ in $1{:} J$\label{alg:mif:sim}\;
      $w_{n,j}^m = f_{Y_n|X_n}(y^*_n| X_{n,j}^{P,m} ; \Theta^{P,m}_{n,j})$ for $j$ in $1{:} J$\label{alg:mif:weights}\;
      Apply \cref{alg:systematic} to draw $k_{1{:}J}$ with $P[k_j=i]=  w_{n,i}^m\Big/\sum_{u=1}^J w_{n,u}^m$\label{alg:mif:syst}\;
      $\Theta^{F,m}_{n,j}=\Theta^{P,m}_{n,k_j}$ and $X^{F,m}_{n,j}=X^{P,m}_{n,k_j}$ for $j$ in $1{:} J$\label{alg:mif:resample}\;
    }
    Set $\Theta^{m}_{j}=\Theta^{F,m}_{N,j}$ for $j$ in $1{:} J$\;
  }
  \KwOut{Final parameter swarm, $\{\Theta^M_j, j=1,\dots,J\}$}
  \KwCplx{$\bigO{J M}$}
\end{algorithm}

Iterated filtering techniques maximize the likelihood obtained by SMC \citep{Ionides2006,Ionides2011,Ionides2015}.
The key idea of iterated filtering is to replace the model we are interested in fitting---which has time-invariant parameters---with a model that is just the same except that its parameters take a random walk in time.
Over multiple repetitions of the filtering procedure, the intensity of this random walk approaches zero and the modified model approaches the original one.
Adding additional variability in this way has four positive effects:
\begin{enumerate}[{A}1.]
\item It smooths the likelihood surface, which facilitates optimization.
\item It combats particle depletion by adding diversity to the population of particles.
\item Small perturbations preserve the mathematical property that, when the parameters are included in the model as latent states, recursive solution of the filtering equations converges to their maximum likelihood estimate (MLE) \citep{Ionides2015}.
\item It preserves the plug-and-play property, inherited from the particle filter.
\end{enumerate}
By analogy with annealing, the random walk intensity can be called a temperature, which is decreased according to a prescribed cooling schedule.
One strives to ensure that the algorithm will freeze at the maximum of the likelihood as the temperature approaches zero.
Iterated filtering is implemented in the \code{mif2} function.
Since \code{pomp} version 2.0, \code{mif2} has superseded the earlier IF1 algorithm \citep{Ionides2006,Ionides2011}.

The perturbations on the parameters in \cref{alg:mif:init:perturb,alg:mif:perturb} of \cref{alg:mif} follow a normal distribution, with each component of the parameter vector $\theta$ perturbed independently.
Neither normality nor independence are necessary for the convergence of the algorithm;
the theory allows for a broad class of perturbation kernels \citep{Ionides2015}.
\code{pomp} does not make use of all of this flexibility:
it does allow arbitrary transformation of the parameter space, providing the \code{partrans} argument for this purpose.

\code{mif2} provides assistance in the specification of the collection of random talk intensities, $\sigma_{0:N,1:\DimTheta}$, via the \code{rw.sd} function.
A parameter $\dimtheta$ for which $\sigma_{0:N,\dimtheta}$ is constant for $n=\seq{0}{N}$ is called a regular parameter (RP).
A parameter $\dimtheta$ for which $\sigma_{1:N,\dimtheta}=0$, so perturbations happen only at time $t_0$, is called an initial value parameter (IVP) since this choice is appropriate for parameters which determine only the initial state of the latent process.
In general, a parameter should be perturbed only during a time interval where it influences the transition or measurement process.
Iterated filtering can be understood by an evolutionary analogy in parameter space, requiring both mutation and selection in order to increase the fitness of the population.
An example of a parameter which is neither an RP nor an IVP is a break-point parameter which describes the time or magnitude of a change in the dynamics or the measurement process.

\Cref{alg:mif:perturb,alg:mif:sim,alg:mif:weights,alg:mif:syst,alg:mif:resample} of \cref{alg:mif} are exactly an application of SMC (\cref{alg:pfilter}) to a modified POMP model in which the parameters are added to the state space.
This approach has been used in a variety of previously proposed POMP methodologies \citep{Kitagawa1998,Liu2001,Wan2000} but iterated filtering is distinguished by having theoretical justification for convergence to the maximum likelihood estimate \citep{Ionides2015}.

\clearpage

\subsection{Particle Markov chain Monte Carlo}
\label{sec:pmcmc}

%% PMCMC PSEUDOCODE
\begin{algorithm}[t!]
  \caption{
    \textbf{Particle Markov chain Monte Carlo}:
    \texttt{pmcmc(P, params{\argequals}$\theta_0$, Nmcmc{\argequals}$M$, Np{\argequals}$J$, proposal{\argequals}mvn\_rw($V$))},
    using notation from \cref{tab:notation}
    where \code{P} is a class-\class{pomp} object with defined methods for
    \code{rprocess}, \code{dmeasure}, \code{rinit}, \code{dprior}, and \code{obs}.
    The supplied \code{proposal} samples from a symmetric, but otherwise arbitrary, MCMC proposal distribution, $q(\theta^P\given\theta)$.
    \label{alg:pmcmc}
  }
  \KwIn{
    Starting parameter, $\theta_0$;
    simulator for $f_{X_0}(x_0\given\theta)$;
    simulator for $f_{X_n|X_{n-1}}(x_n\given x_{n-1}\giventh\theta)$;
    evaluator for $f_{Y_n|X_n}(y_n\given x_{n}\giventh\theta)$;
    simulator for $q(\theta^P\given\theta)$;
    data, $y^*_{1:N}$;
    number of particles, $J$;
    number of filtering operations, $M$;
    proposal variance matrix, $V$;
    evaluator for prior, $f_{\Theta}(\theta)$.
  }
  \BlankLine
  Initialization: compute $\loglikMC(\theta_0)$ using \cref{alg:pfilter} with $J$ particles.\;
  \For {$m$ in $\seq{1}{M}$}{
    Draw a parameter proposal, $\theta^P_m\sim \normal\left(\theta_{m-1},V\right)$.\;
    Compute $\loglikMC(\theta^P_m)$ using \cref{alg:pfilter} with $J$ particles.\;
    Generate $U\sim\mathrm{Uniform}(0,1).$\;
    Set $\big(\theta_m,\loglikMC(\theta_m)\big)=\begin{cases}
    \big(\theta^P_m,\loglikMC(\theta^P_m)\big), &\text{if } U<\displaystyle\frac{f_\Theta(\theta^P_m)\exp(\loglikMC(\theta^P_m))}{f_\Theta(\theta_{m-1})\exp(\loglikMC(\theta_{m-1}))},\\
    \big(\theta_{m-1},\loglikMC(\theta_{m-1})\big),&\text{otherwise.}
    \end{cases}$\;
  }
  \KwOut{
    Samples, $\theta_{1:M}$, representing the posterior distribution, $f_{\Theta|Y_{1:N}}(\theta\given y_{1:N}^*)$.
  }
  \KwCplx{$\bigO{J M}$}
\end{algorithm}

Full information plug-and-play Bayesian inference for POMP models is enabled by particle Markov chain Monte Carlo (PMCMC) algorithms \citep{Andrieu2010}.
PMCMC methods combine likelihood evaluation via SMC with MCMC moves in the parameter space.
The simplest and most widely used PMCMC algorithm, termed particle marginal Metropolis-Hastings (PMMH), is based on the observation that the unbiased likelihood estimate provided by SMC can be plugged into the Metropolis-Hastings update procedure to give an algorithm targeting the desired posterior distribution for the parameters \citep{Andrieu2009}.
PMMH is implemented in \code{pmcmc}, as described in \cref{alg:pmcmc}.
The \code{proposal} argument permits an arbitrary symmetric proposal distribution, but our pseudocode corresponds to the situation where the \code{mvn.rw} plug-in is used, to provide a Gaussian proposal with a specified covariance matrix.
Other plug-in functions include \code{mvn.diag.rw} and \code{mvn.rw.adaptive}, which provides an adaptive proposal distribution.

In part because it gains only a single likelihood evaluation from each particle filtering operation, PMCMC can be computationally relatively inefficient \citep{Bhadra2010,Ionides2015}.
Nevertheless, its invention introduced the possibility of full-information plug-and-play Bayesian inferences in some situations where they had been unavailable.

\subsection{Synthetic likelihood of summary statistics}
\label{sec:probe}

%%%%% SYNTHETIC LIKELIHOOD EVALUATION ALGORITHM
\begin{algorithm}[t!]
  \caption{
    \textbf{Synthetic likelihood evaluation}:
    \protect
    \texttt{probe(P, nsim{\argequals}$J$, probes{\argequals}$\featureFunc$)},
    using notation from \cref{tab:notation}
    where \code{P} is a class-\class{pomp} object with defined methods for
    \code{rprocess}, \code{rmeasure}, \code{rinit}, and \code{obs}.
    \label{alg:probe}
  }
  \KwIn{
    Simulator for $f_{X_{n}|X_{n-1}}(x_{n}\given x_{n-1}\giventh\theta)$;
    simulator for $f_{X_{0}}(x_{0}\giventh\theta)$;
    simulator for $f_{Y_n|X_n}(y_n\given x_{n}\giventh\theta)$;
    parameter, $\theta$;
    data, $y^*_{1:N}$;
    number of simulations, $J$;
    vector of summary statistics or \emph{probes}, $\featureFunc=(\featureFunc_1,\dots,\featureFunc_{\Nprobe})$.
  }
  \BlankLine
  Compute observed probes:
  $s^*=\featureFunc(y^*_{1:N})$.\;
  Simulate $J$ datasets:
  $Y^j_{1:N}\sim f_{Y_{1:N}}(\mydot \giventh \theta)$ for $j$ in $\seq{1}{J}$.\;
  Compute simulated probes:
  $s_{j}=\featureFunc(Y^j_{1:N})$ for $j$ in $\seq{1}{J}$.\;
  Compute sample mean:
  $\mu=J^{-1}\sum_{j=1}^Js_{j}$.\;
  Compute sample covariance:
  $V_{i{\nprobe}}=(J-1)^{-1}\sum_{j=1}^J (s_{ij}-\mu_i)(s_{{\nprobe}j}-\mu_{\nprobe})$ for $i$ and ${\nprobe}$ in $\seq{1}{\Nprobe}$.\;
  Compute the log synthetic likelihood:
  \begin{equation}
    \loglikMC_{\featureFunc}(\theta)=-\frac{1}{2}\,(s^*-\mu)^{\top}{V}^{-1}(s^*-\mu)-\frac{1}{2}\,\log\det{V}-\frac{d}{2}\,\log(2\pi).
  \end{equation}\;
  \KwOut{Synthetic likelihood, $\synloglikMC(\theta)$.}
  \KwCplx{$\bigO{J}$}
\end{algorithm}

Some motivations to estimate parameters based on features rather than the full likelihood include:
\begin{enumerate}[{B}1.]
\item \label{whyFeature2}
  Reducing the data to sensibly selected and informative low-dimensional summary statistics may have computational advantages \citep{Wood2010}.
\item \label{whyFeature1}
  The scientific goal may be to match some chosen characteristics of the data rather than all aspects of it.
  Acknowledging the limitations of all models, this limited aspiration may be all that can reasonably be demanded  \citep{Kendall1999,Wood2001a}.
\item \label{whyFeature3} In conjunction with full-information methodology, consideration of individual features has diagnostic value to determine which aspects of the data are driving the full-information inferences \citep{Reuman2006}.
\item  \label{whyFeature4} Feature-based methods for dynamic models typically do not require the POMP model structure.
  However, that benefit is outside the scope of the \pkg{pomp} package.
\item \label{whyFeature5} Feature-based methods are typically \emph{doubly plug-and-play}, meaning that they require simulation, but not evaluation, for both the latent process transition density and the measurement model.
\end{enumerate}
When pursuing goal~B\ref{whyFeature2}, one aims to find summary statistics which are as close as possible to sufficient statistics for the unknown parameters.
Goals~B\ref{whyFeature1} and~B\ref{whyFeature3} deliberately look for features which discard information from the data;
in this context the features have been called probes \citep{Kendall1999}.
The features are denoted by a collection of functions, $\featureFunc=(\featureFunc_1,\dots,\featureFunc_\Nprobe)$, where each $\featureFunc_\nprobe$ maps an observed time series to a real number.
We write $S=(S_1,\dots,S_\Nprobe)$ for the vector-valued random variable with $S=\featureFunc(Y_{1:N})$, with $f_{S}(s\giventh\theta)$ being the corresponding joint density.
The observed feature vector is $s^*=\featureFunc(y^*_{1:N})$;
for any parameter set one can look for parameter values for which typical features for simulated data match the observed features.
One can define a likelihood function, $\synloglik(\theta)=f_{S}(s^*\giventh\theta)$.
Arguing that $S$ should be approximately multivariate normal, for suitable choices of the features, \citet{Wood2010} proposed using simulations to construct a multivariate normal approximation to $\synloglik(\theta)$, and called this a \emph{synthetic likelihood}.

Simulation-based evaluation of a feature matching criterion is implemented by \code{probe} (\cref{alg:probe}).
The feature matching criterion requires a scale, and a natural scale to use is the empirical covariance of the simulations.
Working on this scale, as implemented by \code{probe}, there is no substantial difference between the probe approaches of \citet{Kendall1999} and \citet{Wood2010}.
Numerical optimization of the synthetic likelihood is achieved via the \code{probe\_objfun}, which constructs a stateful objective function suitable for use with standard optimizers such as \code{subplex} \citep{Rowan1990,subplex} or any of the methods provided by \code{optim} or the \pkg{nloptr} package \citep{Johnson2014,Ypma2014}.


\subsection{Approximate Bayesian computation (ABC)}
\label{sec:abc}

%%% ALGORITHM FOR ABC
\begin{algorithm}[t!]
  \caption{
    \textbf{Approximate Bayesian computation}:
    \protect
    \texttt{abc(P, params{\argequals}$\theta_0$, Nmcmc{\argequals}$M$, probes{\argequals}$\featureFunc$, scale{\argequals}$\tau_{1:\Nprobe}$, proposal{\argequals}mvn\_rw($V$), epsilon{\argequals}$\epsilon$)},
    using notation from \cref{tab:notation}, where
    \code{P} is a class-\class{pomp} object with defined methods for
    \code{rprocess}, \code{rmeasure}, \code{rinit}, \code{dprior}, and \code{obs}.
    \label{alg:abc}
  }
  \KwIn{
    Starting parameter, $\theta_0$;
    simulator for $f_{X_0}(x_0\giventh\theta)$;
    simulator for $f_{X_n|X_{n-1}}(x_n\given x_{n-1}\giventh\theta)$;
    simulator for $f_{Y_n|X_n}(y_n\given x_{n}\giventh\theta)$;
%    simulator for $q(\theta^P\given\theta)$;
    data, $y^*_{1:N}$;
    number of proposals, $M$;
    vector of probes, $\featureFunc=(\featureFunc_1,\dots,\featureFunc_{\Nprobe})$;
    proposal variance matrix, $V$;
    evaluator for prior, $f_{\Theta}(\theta)$; feature scales, $\tau_{1:{\Nprobe}}$;
    tolerance, $\epsilon$.
  }
  \BlankLine
  Compute observed probes:
  $s^*=\featureFunc(y^*_{1:N})$.\;
  \For {$m$ in $\seq{1}{M}$}{
    Draw a parameter proposal, $\theta^P_m \sim \normal\left(\theta_{m-1},V\right)$.\;
    Simulate dataset:
    $Y_{1:N}\sim f_{Y_{1:N}}(\mydot\giventh\theta^P_{m})$.\;
    Compute simulated probes:
    $s=\featureFunc(Y_{1:N})$.\;
    Generate $U\sim\mathrm{Uniform}(0,1).$\;
    Set $\theta_m=\begin{cases}
    \theta^P_m,  &\text{if } \displaystyle \sum_{\nprobe=1}^{\Nprobe}\left(\frac{s_{\nprobe}-s_{\nprobe}^*}{\tau_{\nprobe}}\right)^2<\epsilon^2 \text{ and }
    \displaystyle U<\frac{f_\Theta(\theta^P_m)}{f_\Theta(\theta_{m-1})},\\
    \theta_{m-1}, &\text{otherwise.}
    \end{cases}\nllabel{alg:abc:epsilon}$\;
  }
  \KwOut{
    Samples, ${\theta_{1:M}}$, representing the posterior distribution, $f_{\Theta|S}(\theta\given{s^*})$.
  }
  \KwCplx{Nominally $\bigO{M}$, but performance will depend on the choice of $\epsilon$, $\tau_{\nprobe}$, and $V$, as well as on the choice of probes $\featureFunc$.}
\end{algorithm}

ABC algorithms are Bayesian feature-matching techniques, comparable to the frequentist generalized method of moments \citep{Marin2012}.
The vector of summary statistics $\featureFunc$, the corresponding random variable $S$, and the value $s^*=\featureFunc(y^*_{1:N})$, are defined as in \cref{sec:probe}.
The goal of ABC is to approximate the posterior distribution of the unknown parameters given $S=s^*$.
ABC has typically been motivated by computational considerations, as in point~B\ref{whyFeature2} of \cref{sec:probe} \citep{Sisson2007,Toni2009,Beaumont2010}.
Points~B\ref{whyFeature1} and~B\ref{whyFeature3} also apply \citep{Ratmann2009}.

The key theoretical insight behind ABC algorithms is that an unbiased estimate of the likelihood can be substituted into a Markov chain Monte~Carlo algorithm to target the required posterior, the same result that justifies PMCMC \citep{Andrieu2009}.
However, ABC takes a different approach to approximating the likelihood.
The likelihood of the observed features, $\loglik_S(\theta)=f_{S}(s^*\giventh\theta)$, has an approximately unbiased estimate based on a single Monte~Carlo realization $Y_{1:N}\sim f_{Y_{1:N}}(\mydot\giventh\theta)$ given by
\begin{equation}
  \label{eq:abc-lik}
  \synloglikMC^{ABC}(\theta)=\begin{cases}
  \epsilon^{-{\Nprobe}}B_{\Nprobe}^{-1}\displaystyle\prod_{\nprobe=1}^{\Nprobe} \tau_{\nprobe},
  & \text{if } \displaystyle\sum_{\nprobe=1}^{\Nprobe}\left(\frac{s_{\nprobe}-s_{\nprobe}^*}{\tau_{\nprobe}}\right)^2 < \epsilon^2, \\
  0, & \text{otherwise,}
  \end{cases}
\end{equation}
where $B_{\Nprobe}$ is the volume of the $\Nprobe$-dimensional unit ball and $\tau_{\nprobe}$ is a scaling chosen for the $\nprobe$-th feature.
The likelihood approximation in \cref{eq:abc-lik} differs from the synthetic likelihood in \cref{alg:probe} in that only a single simulation is required.
As $\epsilon$ becomes small, the bias in \cref{eq:abc-lik} decreases but the Monte Carlo variability increases.
The ABC implementation \code{abc} (presented in \cref{alg:abc}) is a random walk Metropolis implementation of ABC-MCMC \citep[Algorithm 3 of][]{Marin2012}.
In the same style as iterated filtering and PMCMC, we assume a Gaussian random walk in parameter space; the package supports alternative choices of the proposal distribution.


\subsection{Nonlinear forecasting}
\label{sec:nlf}

%%%%% NLF QUASI LIKELIHOOD ALGORITHM %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{algorithm}[t!]
  \caption{
    \textbf{Simulated quasi log likelihood for NLF}.
    Pseudocode for the  quasi-likelihood function returned by \texttt{nlf\_objfun(\,P,\,params{\argequals}$\theta_0$, ti{\argequals}$t_i$, tf{\argequals}$t_f$, nrbf{\argequals}$K$, lags{\argequals}$\lags_{1:L}$)}.
    Using notation from \cref{tab:notation}, \code{P} is a class-\class{pomp} object with defined methods for \code{rprocess}, \code{rmeasure}, \code{rinit}, and \code{obs}.
    \label{alg:nlf}
  }
  \KwIn{
    Simulator for $f_{X_{n}|X_{n-1}}(x_{n}\given x_{n-1}\giventh\theta)$;
    simulator for $f_{X_{0}}(x_{0}\giventh\theta)$;
    simulator for $f_{Y_n|X_n}(y_n\given x_{n}\giventh\theta)$;
    parameter, $\theta$;
    data, $y^*_{1:N}$;
    collection of lags, $\lags_{1:L}$;
    sampling frequency, $\nu$;
    length of discarded transient, $B=\nu\,(t_i-t_0)$;
    length of simulation, $J=\nu\,(t_f-t_i)$;
    number of radial basis functions, $K$.
  }
  Simulate long stationary time series:
  $Y_{1:(B+J)}\sim f_{Y_{1:(B+J)}}(\mydot\giventh\theta)$.\;
  Set $Y_{\min}=\min\{Y_{(B+1):(B+J)}\}$, $Y_{\max}=\max\{Y_{(B+1):(B+J)}\}$ and $R=Y_{\max}-Y_{\min}$.\;
  Locations for basis functions:
  $m_k=Y_{\min} + R\times [1.2\times (k-1)(K-1)^{-1}-0.1]$ for $k$ in $\seq{1}{K}$.\label{alg:nlf:rbf:params1}\;
  Scale for basis functions:
  $s=0.3\times R$ \label{alg:nlf:rbf:params2}.\;
  Define radial basis functions:
  $f_k(x)=\exp\{(x-m_k)^2/2s^2\}$ for $k$ in $\seq{1}{K}$.\label{alg:nlf:rbf}\;
  Define prediction function:
  $H(y_{n-\lags_1},y_{n-\lags_2},\dots,y_{n-\lags_L})=\sum_{j=1}^L\sum_{k=1}^K a_{jk}f_k(y_{n-\lags_j})$.\;
  Compute $\{a_{jk}: j\in\seq{1}{L}, k\in\seq{1}{K}\}$ to minimize
  \begin{equation}
    \hat\sigma^2=\frac{1}{J} \sum_{n=B+1}^{B+J} \big[ Y_n - H(Y_{n-\lags_1},Y_{n-\lags_2},\dots,Y_{n-\lags_L})\big]^2.
  \end{equation}\;
  Compute the simulated quasi log likelihood:
  \begin{equation}
    \loglikMC_{Q}(\theta)=-\frac{N-\maxlag}{2}\log 2\pi\hat\sigma^2-\sum_{n=1+\maxlag}^{N}\!\frac{\big[y_n^*-H(y^*_{n-\lags_1},y^*_{n-\lags_2},\dots,y^*_{n-\lags_L})\big]^2}{2\hat\sigma^2},
  \end{equation}
  where $\maxlag=\max(\lags_{1:L}).$\;
  \KwOut{Simulated quasi log likelihood, $\loglikMC_Q(\theta)$.}
  \KwCplx{$\bigO{B}+\bigO{J}$}
\end{algorithm}

%Under a set of regularity conditions, it can be shown that
%$\hat{\theta}_{n}$ converges in probability (as $n$ grows large)
%to a vector of `pseudo' true values $\theta$.

Nonlinear forecasting (NLF) uses simulations to build up an approximation to the one-step prediction distribution that is then evaluated on the data.
We saw in \cref{sec:pfilter} that SMC evaluates the prediction density for the observation, $f_{Y_n|Y_{1:{n-1}}}(y_n^*\given y_{1:n-1}^*\giventh \theta)$, by first building an approximation to the prediction density of the latent process, $f_{X_n|Y_{1:{n-1}}}(x_n\given y_{1:n-1}^*\giventh \theta)$.
By contrast, NLF uses simulations to fit a linear regression of $Y_n$ on the $L$ variables $Y_{n-\lags_1}$, \dots, $Y_{n-\lags_L}$, for some choice of positive lags $\lags_{1:L}$.
The prediction errors when this model is applied to the data give rise to a quantity called the quasi-likelihood, which behaves for many purposes like a likelihood \citep{Smith1993}.
The implementation in \code{nlf} maximizes the quasi-likelihood computed in \cref{alg:nlf}, using the subplex method \citep{Rowan1990,subplex} or any other optimizer offerered by \code{optim}.
The construction of the quasi-likelihood in \code{nlf} follows the specific recommendations of \citet{Kendall2005}.
In particular, the choice of radial basis functions, $f_k$, in \cref{alg:nlf:rbf} and the specification of $m_k$ and $s$ in \cref{alg:nlf:rbf:params1,alg:nlf:rbf:params2} were proposed by \citet{Kendall2005} based on trial and error.
The quasi-likelihood is mathematically most similar to a likelihood when $\min(\lags_{1:L})=1$, so that $\loglik_{Q}(\theta)$ approximates the factorization of the likelihood in \cref{eq:loglik:factorization}.
With this in mind, it is natural to choose contiguous lags $\lags_{1:L}=1:L$.
However, \citet{Kendall2005} found that a two-step prediction criterion, with $\min(\lags_{1:L})=2$, led to improved numerical performance.
It is natural to ask when one might choose to use quasi-likelihood estimation in place of full likelihood estimation implemented by SMC.
Some considerations follow, closely related to the considerations for the synthetic likelihood and ABC (\cref{sec:abc,sec:probe}):
\begin{enumerate}[{C}1.]
\item \label{whyNLF1}
  NLF benefits from stationarity since (unlike SMC) it uses all time points in the simulation to build a prediction rule valid at all time points.
  Indeed, NLF has not been considered applicable for non-stationary models and, on account of this, \code{nlf} is not appropriate if the model includes time-varying covariates.
  An intermediate scenario between stationarity and full non-stationarity is seasonality, where the dynamic model is forced by cyclical covariates, and this is supported by \code{nlf} (cf.~B\ref{whyFeature2} in \cref{sec:probe}).
\item  \label{whyNLF2}  Potentially, quasi-likelihood could be preferable to full likelihood in some situations.
  It has been argued that a two-step prediction criterion may sometimes be more robust than the likelihood to model misspecification \citep{Xia2011} (cf.~B\ref{whyFeature1}).
\item\label{whyNLF3}
  Arguably, two-step prediction should be viewed as a diagnostic tool that can be used to complement full likelihood analysis rather than replace it \citep{Ionides2011b} (cf.~B\ref{whyFeature3}).
\item \label{whyNLF4} NLF does not require that the model be Markovian (cf.~B\ref{whyFeature4}), although the \pkg{pomp} implementation, \code{nlf}, does.
\item \label{whyNLF5} NLF is doubly plug-and-play (cf.~B\ref{whyFeature5}).
\item\label{whyNLF6} The regression surface reconstruction carried out by NLF does not scale well with the dimension of the observed data.
  NLF is recommended only for low-dimensional time series observations.
\end{enumerate}
NLF can be viewed as an estimating equation method, and so standard errors can be computed by standard sandwich estimator or bootstrap techniques \citep{Kendall2005}.
The optimization in NLF is typically carried out with a fixed seed for the random number generator, so the simulated quasi-likelihood is a deterministic function. If \code{rprocess} depends smoothly on the random number sequence and on the parameters, and the number of calls to the random number generator does not depend on the parameters, then fixing the seed results in a smooth objective function.
However, some common components to model simulators, such as \code{rnbinom}, make different numbers of calls to the random number generator depending on the arguments, which introduces nonsmoothness into the objective function.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Model construction and data analysis: Simple examples}
\label{sec:examples}

\subsection{A first example: The Gompertz model}
\label{sec:gompertz:setup}

The plug-and-play methods in \pkg{pomp} were designed to facilitate data analysis based on complicated models, but we will first demonstrate the basics of \pkg{pomp} using simple discrete-time models, the Gompertz and Ricker models for population growth \citep{Reddingius1971,Ricker1954}.
The Ricker model will be introduced in \cref{sec:ricker:setup} and used in \cref{sec:ricker:probe.match}; the remainder of \cref{sec:examples} will use the Gompertz model.
The Gompertz model postulates that the density, $X_{t+\Delta{t}}$, of a population of organisms at time $t+\Delta{t}$ depends on the density, $X_{t}$, at time $t$ according to
\begin{equation}
  \label{eq:gompertz1}
  X_{t+\Delta{t}}=\carryingCapacity^{1-e^{-r\,\Delta{t}}}\,X_{t}^{e^{-r\,\Delta{t}}}\,\varepsilon_{t}.
\end{equation}
In \cref{eq:gompertz1}, $\carryingCapacity$ is the carrying capacity of the population, $r$ is a positive parameter, and the $\varepsilon_{t}$ are independent and identically-distributed lognormal random variables with $\log\varepsilon_t\sim\normal(0,\sigma^2)$.
Additionally, we will assume that the population density is observed with errors in measurement that are lognormally distributed:
\begin{equation}
  \label{eq:gompertz-obs}
  \log{Y_{t}}\;\sim\;\normal\left(\log{X_{t}},\tau^2\right).
\end{equation}
Taking a logarithmic transform of \cref{eq:gompertz1} gives
\begin{equation}
  \label{eq:gompertz2}
  \log{X_{t+\Delta{t}}}\;\sim\;\normal\left(\left(1-e^{-r\,\Delta{t}}\right)\,\log{\carryingCapacity}+e^{-r\,\Delta{t}}\,\log{X_t},\sigma^2\right).
\end{equation}
On this transformed scale, the model is linear and Gaussian and so we can obtain exact values of the likelihood function by applying the Kalman filter.
Plug-and-play methods are not strictly needed;
this example therefore allows us to compare the results of generally applicable plug-and-play methods with exact results from the Kalman filter.
Later we will look at the Ricker model and a continuous-time model for which no such special tricks are available.

The first step in implementing this model in \pkg{pomp} is to construct an \proglang{R} \citep{R} object of class \class{pomp} that encodes the model and the data.
This involves the specification of functions to do some or all of \code{rprocess}, \code{rmeasure}, and \code{dmeasure}, along with data and (optionally) other information.
The documentation (\code{?pomp}) spells out the usage of the \code{pomp} constructor, including detailed specifications for all its arguments and links to several examples.

To begin, we will write a function that implements the process model simulator.
This is a function that will simulate a single step ($t\to{t+\Delta{t}}$) of the unobserved process (\cref{eq:gompertz1}).
<<gomp1-comment,include=FALSE>>=
##' ## Constructing a pomp object.
##' The following codes construct the basic elements of the Gompertz model
##' and construct the 'gompertz' pomp object.
<<gomp1>>=
gompertz.rproc <- function (X,r,K,sigma,...,delta.t) {
  eps <- exp(rnorm(n=1,mean=0,sd=sigma))
  S <- exp(-r*delta.t)
  c(X=K^(1-S)*X^S*eps)
}
@
The translation from the mathematical description (\cref{eq:gompertz1}) to the simulator is straightforward.
When this function is called, the argument \code{x} contains the state at time \code{t}.
The parameters (including $\carryingCapacity$, $r$, and $\sigma$) are passed in the argument \code{params}.
Notice that \code{x} and \code{params} are named numeric vectors and that the output must likewise be a named numeric vector, with names that match those of \code{x}.
%% The algorithms in \pkg{pomp} all make heavy use of the \code{names} attributes of vectors and matrices.
The argument \code{delta.t} specifies the time-step size.
In this case, the time-step will be 1 unit;
we will see below how this is specified.

Next, we will implement a simulator for the observation process, \cref{eq:gompertz-obs}.
<<gomp2>>=
gompertz.rmeas <- function (X, tau, ...) {
  c(Y=rlnorm(n=1,meanlog=log(X),sdlog=tau))
}
@
Again the translation from the measurement model \cref{eq:gompertz-obs} is straightforward.
When the function \code{gompertz.rmeas} is called, the named numeric vector \code{x} will contain the unobserved states at time \code{t};
\code{params} will contain the parameters as before.
This return value will be a named numeric vector containing a single draw from the observation process (\cref{eq:gompertz-obs}).

Complementing the measurement model simulator is the corresponding measurement model density, which we implement as follows:
<<gomp3>>=
gompertz.dmeas <- function (tau, X, Y, ..., log) {
  dlnorm(x=Y,meanlog=log(X),sdlog=tau,log=log)
}
@
We will need this later on for inference using \code{pfilter}, \code{mif} and \code{pmcmc}.
When the function \code{gompertz.dmeas} is called, \code{y} will contain the observation at time \code{t}, \code{x} and \code{params} will be as before, and the parameter \code{log} will indicate whether the likelihood (\code{log = FALSE}) or the log likelihood (\code{log = TRUE}) is required.

With the above in place, we build a class-\class{pomp} object via a call to \code{pomp}:
<<gomp5>>=
gomp <- pomp(
  data=data.frame(time=1:100, Y=NA), times="time", t0=0,
  rprocess=discrete_time(step.fun=gompertz.rproc, delta.t=1),
  rmeasure=gompertz.rmeas,
  statenames="X",
  paramnames=c("r", "K", "sigma", "tau", "X_0"))
@
The first argument (\code{data}) specifies a data frame that holds the data and the times at which the data were observed.
Since this is a toy problem, we have as yet no data;
in a moment, we will generate some simulated data.
The second argument (\code{times}) specifies which of the columns of \code{data} is the time variable.
The \code{rprocess} argument specifies that the process model simulator will be in discrete time, with each step of duration \code{delta.t} taken by the function given in the \code{step.fun} argument.
The \code{rmeasure} argument specifies the measurement model simulator function.
\code{t0} fixes $t_0$ for this model;
here we have chosen this to be one time unit prior to the first observation.

It is worth noting that implementing the \code{rprocess}, \code{rmeasure}, and \code{dmeasure} components as \proglang{R} functions, as we have done above, leads to needlessly slow computation.
As we will see below, \pkg{pomp} provides facilities for specifying the model in \proglang{C}, which can accelerate computations manyfold.

Before we can simulate from the model, we need to specify some parameter values.
The parameters must be a named numeric vector containing at least all the parameters referenced by the functions \code{gompertz.rproc} and \code{gompertz.rmeas}.
The parameter vector needs to determine the initial condition $X(t_{0})$ as well.
Let us take our parameter vector to be
<<gomp6>>=
theta <- c(r=0.1,K=1,sigma=0.1,tau=0.1, X_0=1)
@
The parameters $r$, $\carryingCapacity$, $\sigma$, and $\tau$ appear in \code{gompertz.rproc} and \code{gompertz.rmeas}.
The initial condition $X_0$ is also given in \code{theta}.
The fact that the initial condition parameter's name ends in \code{_0} is significant:
it tells \code{pomp} that this is the initial condition of the state variable \code{X}.
This use of the \code{_0} suffix is the default behavior of \code{pomp}:
one can however parameterize the initial condition distribution arbitrarily using \code{pomp}'s optional \code{rinit} argument.

We can now simulate the model at these parameters:
<<gomp7-setup,echo=FALSE,results="hide">>=
set.seed(340398091L)
<<gomp7>>=
gomp <- simulate(gomp, rinit=function(X_0,...){c(X=X_0)}, params=theta)
@
Now \code{gomp} is identical to what it was before, except that the missing data have been replaced by simulated data.
The parameter vector (\code{theta}) at which the simulations were performed has also been saved internally to \code{gomp}.
We can plot the simulated data via
<<gomp8,eval=FALSE,purl=FALSE>>=
plot(gomp, variables = "Y")
@
\Cref{fig:gompertz-first-simulation-plot} shows the results of this operation.

\begin{figure}[t!]
  <<gompertz-plot,echo=FALSE,fig.height=3,fig.width=5>>=
  op <- par(mar=c(3,3,2,0),mgp=c(2,1,0))
  plot(Y~time,data=as.data.frame(gomp),type="l")
  par(op)
  @
  \caption{
    Simulated data from the Gompertz model (\cref{eq:gompertz1,eq:gompertz-obs}).
    This figure shows the result of executing \code{plot(gomp, variables = "Y")}.
  }
  \label{fig:gompertz-first-simulation-plot}
\end{figure}


\subsection{Computing the likelihood using SMC}

As discussed in \cref{sec:methods}, some parameter estimation algorithms in the \pkg{pomp} package are doubly plug-and-play in that they require only \code{rprocess} and \code{rmeasure}.
These include the nonlinear forecasting algorithm \code{nlf}, the probe-matching algorithm (\code{probe\_objfun}), and approximate Bayesian computation via \code{abc}.
The plug-and-play full-information methods in \pkg{pomp}, however, require \code{dmeasure}, i.e., the ability to evaluate the likelihood of the data given the unobserved state.
The \code{gompertz.dmeas} above does this, but we must fold it into the class-\class{pomp} object in order to use it.
We can do this with another call to \code{pomp}:
<<gomp9-comment,include=FALSE>>=
##' ## The particle filter
##' First, add in the measurement density function.
@
<<gomp9>>=
gomp <- pomp(gomp,dmeasure=gompertz.dmeas)
@
The result of the above is a new class-\class{pomp} object \code{gomp} in every way identical to the one we had before, but with the measurement-model density function \code{dmeasure} now specified.

To estimate the likelihood of the data, we can use the function \code{pfilter}, an implementation of \cref{alg:pfilter}.
We must decide how many concurrent realizations (\emph{particles}) to use:
the larger the number of particles, the smaller the Monte Carlo error but the greater the computational burden.
Here, we run \code{pfilter} with 1000 particles to estimate the likelihood at the true parameters:
<<pfilter1-setup,eval=TRUE,echo=FALSE,results="hide">>=
##' Compute the approximate log likelihood using the particle filter.
set.seed(334388458L)
<<pfilter1-calc,eval=TRUE,cache=TRUE,results="markup",echo=TRUE>>=
pf <- pfilter(gomp,params=theta,Np=1000)
loglik.truth <- logLik(pf)
loglik.truth
<<pfilter1-followup,echo=FALSE,results="hide",eval=TRUE,cache=TRUE>>=
##' Construct some functions to compute exact likelihoods for this model
##' using the Kalman filter.
kalman.filter <- function (Y, X0, r, K, sigma, tau) {
  ntimes <- length(Y)
  sigma.sq <- sigma^2
  tau.sq <- tau^2
  cond.loglik <- numeric(ntimes)
  filter.mean <- numeric(ntimes)
  pred.mean <- numeric(ntimes)
  pred.var <- numeric(ntimes)
  m <- log(X0)
  v <- 0
  S <- exp(-r)
  for (k in seq_len(ntimes)) {
    pred.mean[k] <- M <- (1-S)*log(K) + S*m
    pred.var[k] <- V <- S*v*S+sigma.sq
    q <- V+tau.sq
    r <- log(Y[k])-M
    cond.loglik[k] <- dnorm(x=log(Y[k]),mean=M,sd=sqrt(q),log=TRUE)-log(Y[k])
    q <- 1/V+1/tau.sq
    filter.mean[k] <- m <- (log(Y[k])/tau.sq+M/V)/q
    v <- 1/q
  }
  list(
    pred.mean=pred.mean,
    pred.var=pred.var,
    filter.mean=filter.mean,
    cond.loglik=cond.loglik,
    loglik=sum(cond.loglik)
  )
}

##' 'kalman' evaluates gompertz likelihood parameters X0 and K are fixed at 1.
##' Other parameters are taken from x (or, if not in x, from params).
kalman <- function (x, object, params) {
  Y <- obs(object)
  p <- params
  p[names(x)] <- x
  X0 <- 1
  r <- p["r"]
  K <- 1
  sigma <- p["sigma"]
  tau <- p["tau"]
  -kalman.filter(Y, X0, r, K, sigma, tau)$loglik
}

##' Exact log likelihood at the true parameters
exact.loglik.truth <- -kalman(coef(gomp),gomp,coef(gomp))
@
Since the true parameters (i.e., the parameters that generated the data) are stored within the class-\class{pomp} object \code{gomp} and can be extracted by the \code{coef} function, we could have done
<<pfilter2-calc,eval=FALSE,purl=FALSE>>=
pf <- pfilter(gomp,params=coef(gomp),Np=1000)
@
or simply
<<pfilter3-calc,eval=FALSE,purl=FALSE>>=
pf <- pfilter(gomp,Np=1000)
@
Now let us compute the log likelihood at a different point in parameter space, one for which $r$, $K$, and $\sigma$ are each 50\% higher than their true values.
<<pfilter4-setup,eval=TRUE,echo=FALSE,results="hide">>=
set.seed(334388458L)
##' Approximate log likelihood at an arbitrary parameter point
<<pfilter4-calc,eval=TRUE,results="markup",cache=TRUE>>=
theta.guess <- theta.true <- coef(gomp)
theta.guess[c("r","K","sigma")] <- 1.5 * theta.true[c("r","K","sigma")]
pf <- pfilter(gomp,params=theta.guess,Np=1000)
loglik.guess <- logLik(pf)
loglik.guess
@
In this case, the Kalman filter computes the exact log likelihood at the true parameters to be $\Sexpr{round(exact.loglik.truth,2)}$,
while the particle filter with 1000 particles gives $\Sexpr{round(loglik.truth,2)}$.
Since the particle filter gives an unbiased estimate of the likelihood, the difference is due to Monte Carlo error in the particle filter.
One can reduce this error by using a larger number of particles and/or by re-running \code{pfilter} multiple times and averaging the resulting estimated likelihoods.
The latter approach has the advantage of allowing one to estimate the Monte Carlo error itself;
we will demonstrate this in \cref{sec:gompertz:mif}.

\subsection{Maximum likelihood estimation via iterated filtering}
\label{sec:gompertz:mif}

Let us use the iterated filtering approach described in \cref{sec:mif} to obtain an approximate maximum likelihood estimate for the data in \code{gomp}.
Since the parameters of \cref{eq:gompertz1,eq:gompertz-obs} are constrained to be positive, when estimating, we transform them to a scale on which they are unconstrained.
The following implements these transformations.
<<gompertz-transforms>>=
gomp <- pomp(
  gomp,
  partrans = parameter_trans(log=c("r","K","sigma","tau")),
  paramnames=c("r","K","sigma","tau")
)
@

The following code initializes the iterated filtering algorithm at several starting points around \code{theta.true} and estimates the parameters $r$, $\tau$, and $\sigma$.
<<gompertz-mif-setup,include=FALSE,purl=TRUE>>=
##' ## Iterated filtering.
##' First, retrieve the precompiled version of 'gompertz': much faster than
##' the one just constructed.
##' Simulate data to match the ones created before.
dat1 <- as.data.frame(gomp)
const_gomp <- gomp
gomp <- gompertz()
gomp <- simulate(window(gomp,start=1),params=coef(const_gomp),seed=340398091L)
dat2 <- as.data.frame(gomp)
stopifnot(all.equal(dat1[c("time","Y")],dat2[c("time","Y")]))
theta <- coef(gomp)
theta.true <- theta
@
<<gompertz-mif-inner1,echo=FALSE,eval=FALSE,purl=FALSE>>=
theta.guess <- theta.true
theta.guess[estpars] <- rlnorm(n = length(estpars),
  meanlog = log(theta.guess[estpars]), sdlog = 1)
@
<<gompertz-mif-inner2,echo=FALSE,eval=FALSE,purl=FALSE>>=
mif2(gomp, Nmif = 100, params = theta.guess, Np = 2000,
  cooling.fraction.50 = 0.7,
  rw.sd = rw_sd(r=0.02, sigma=0.02,tau=0.02))
@
<<gompertz-mif-inner3,echo=FALSE,eval=FALSE,purl=FALSE>>=
pf <- replicate(n = 10, logLik(pfilter(mf, Np = 10000)))
logmeanexp(pf)
@
<<gompertz-mif-estpar,eval=FALSE,purl=FALSE,echo=FALSE>>=
estpars <- c("r", "sigma", "tau")
@
<<gompertz-mif-post,eval=FALSE,purl=FALSE,echo=FALSE>>=
mf1 <- mif1[[which.max(pf1)]]
theta.mif <- coef(mf1)
loglik.mif <- replicate(n = 10, logLik(pfilter(mf1,Np = 10000)))
loglik.mif <- logmeanexp(loglik.mif,se=TRUE)
theta.true <- coef(gomp)
loglik.true <- replicate(n = 10, logLik(pfilter(gomp, Np = 20000)))
loglik.true <- logmeanexp(loglik.true,se=TRUE)
@
<<gompertz-mif-demo,eval=FALSE,purl=FALSE,echo=TRUE,tidy=FALSE>>=
<<gompertz-mif-estpar>>
library("foreach")
mif1 <- foreach(i = 1:10, .combine = c) %dopar% {
  <<gompertz-mif-inner1>>
  <<gompertz-mif-inner2>>
}
pf1 <- foreach(mf = mif1, .combine = c) %dopar% {
  <<gompertz-mif-inner3>>
}
@
Note that the positivity of parameters is enforced by the transformations we have included in \code{gomp}.
Note also that we have used the \pkg{foreach} package \citep{Kane2013,foreach} to parallelize the computations.
<<gompertz-mif-eval,echo=FALSE,results="hide",cache=FALSE>>=
##' Perform some iterated filtering.
##' These calculations took about 68 sec on my 16-core Intel Xeon 2.90GHz machine.
stew(file="gompertz-mif.rda",seed=334388458L,kind="L'Ecuyer",{

  library(doParallel)
  library(foreach)
  registerDoParallel()

  <<gompertz-mif-estpar>>

  tic <- Sys.time()
  mif1 <- foreach(i=1:10,
    .inorder=FALSE,.packages="pomp",.combine = c,
    .options.multicore=list(set.seed=TRUE)) %dopar% {
    <<gompertz-mif-inner1>>
    <<gompertz-mif-inner2>>
  }

  pf1 <- foreach(mf=mif1,
  .inorder=TRUE,.packages="pomp",.combine = c,
  .options.multicore=list(set.seed=TRUE)) %dopar% {
    <<gompertz-mif-inner3>>
   }
  toc <- Sys.time()
  mifTime <- toc-tic

  <<gompertz-mif-post>>

  kalm.fit1 <- optim(
    par=theta.guess[estpars],
    fn=kalman,
    object=gomp,
    params=coef(gomp),
    hessian=TRUE,
    control=list(trace=2)
  )

  theta.mle <- kalm.fit1$par
  exact.loglik.maximized <- -kalm.fit1$value
  exact.loglik.mif1 <- -kalman(coef(mf1),gomp,coef(gomp))

  mle.po <- gomp
  coef(mle.po,names(theta.mle)) <- unname(theta.mle)
  loglik.mle <- replicate(n=10,logLik(pfilter(mle.po,Np=20000)))
  loglik.mle <- logmeanexp(loglik.mle,se=TRUE)
})
<<gompertz-mif-results,echo=FALSE,eval=TRUE,results="hide">>=
##' Print out the comparison table.
rbind(
      `Truth`=c(signif(theta.true[estpars],3),round(loglik.true,2),round(exact.loglik.truth,2)),
      `\\code{mif} MLE`=c(signif(theta.mif[estpars],3),round(loglik.mif,2),round(exact.loglik.mif1,2)),
      `Exact MLE`=c(signif(theta.mle[estpars],3),round(loglik.mle,2),round(exact.loglik.maximized,2))
     ) -> results.table
pretty.pars <- c(r="$r$",sigma="$\\sigma$",tau="$\\tau$")
colnames(results.table) <- c(pretty.pars[estpars],"$\\loglikMC$","s.e.","$\\loglik$")
@

Each of the 10 \code{mif} runs ends up with a different point estimate (\cref{fig:mif-plot}).
We focus on that with the highest estimated likelihood, having evaluated the likelihood several times to reduce the Monte Carlo error in the likelihood evaluation.
The particle filter produces an unbiased estimate of the likelihood;
therefore, we will average the likelihoods, not the log likelihoods.
<<mif3,echo=TRUE,eval=FALSE,purl=FALSE>>=
<<gompertz-mif-post>>
@

\begin{figure}[t!]
<<mif-plot,echo=FALSE,cache=TRUE,fig.height=6>>=
##' Plot the 'mif' diagnostics.
op <- par(mfrow=c(4,1),mar=c(3,4,0.3,0),mgp=c(2,1,0),
          bty="l",cex.axis=1.2,cex.lab=1.4)
loglik <- do.call(cbind, traces(mif1, "loglik"))
log.r <- do.call(cbind, traces(mif1, "r"))
log.sigma <- do.call(cbind, traces(mif1, "sigma"))
log.tau <- do.call(cbind, traces(mif1, "tau"))
matplot(loglik,type="l",lty=1,xlab="",ylab=expression(log~L),xaxt="n",ylim=max(loglik,na.rm=T)+c(-30,3))
matplot(log.r,type="l",lty=1,xlab="",ylab=expression(log~r),xaxt="n")
matplot(log.sigma,type="l",lty=1,xlab="",ylab=expression(log~sigma),xaxt="n")
matplot(log.tau,type="l",lty=1,xlab="mif iteration",ylab=expression(log~tau))
par(op)
@
\caption{
  Convergence plots can be used to help diagnose convergence of the iterated filtering (IF) algorithm.
  These and additional diagnostic plots are produced when \code{plot} is applied to a \class{mif} or \class{mifList} object.
  \label{fig:mif-plot}
}
\end{figure}

For the calculation above, we have replicated the iterated filtering search, made a careful estimation of the log likelihood, $\loglikMC$, and its standard error using \code{pfilter} at each of the resulting point estimates, and then chosen the parameter corresponding to the highest likelihood as our numerical approximation to the maximum likelihood estimate (MLE).
Taking advantage of the Gompertz model's tractability, we also use the Kalman filter to maximize the exact log likelihood, $\loglik$, and evaluate it at the estimated MLE obtained by \code{mif}.
The resulting estimates are shown in \cref{tab:gompertz-multi-mif-table}.
Usually, the last row and column of \cref{tab:gompertz-multi-mif-table} would not be available even for a simulation study validating the inference methodology for a known POMP model.
In this case, we see that the \code{mif} procedure is successfully maximizing the likelihood up to an error of about 0.1 log units.

\begin{table}[t!]
  \begin{center}
    <<gompertz-multi-mif-table,echo=FALSE,results="asis">>=
    library(xtable)
    options(
    xtable.sanitize.text.function=function(x)x,
    xtable.floating=FALSE
    )
    print(xtable(results.table,align="r|cccccc",digits=c(0,4,4,4,2,2,2)))
    @
  \end{center}
  \caption{
    Results of estimating parameters $r$, $\sigma$, and $\tau$ of the Gompertz model (\cref{eq:gompertz1,eq:gompertz-obs}) by maximum likelihood using iterated filtering (\cref{alg:mif}), compared with the exact MLE and with the true value of the parameter.
    The first three columns show the estimated values of the three parameters.
    The next two columns show the log likelihood, $\loglikMC$, estimated by SMC (\cref{alg:pfilter}) and its standard error, respectively.
    The exact log likelihood, $\ell$, is shown in the rightmost column.
    An ideal likelihood-ratio $95\%$ confidence set, not usually computationally available, includes all parameters having likelihood within \code{qchisq(0.95, df = 3)/2 = 3.91} of the exact MLE.
    We see that both the \code{mif} MLE and the truth are in this set.
    In this example, the \code{mif} MLE is close to the exact MLE, so it is reasonable to expect that profile likelihood confidence intervals and likelihood ratio tests constructed using the \code{mif} MLE have statistical properties similar to those based on the exact MLE.
    \label{tab:gompertz-multi-mif-table}
  }
\end{table}


\subsection{Full information Bayesian inference via PMCMC}
\label{sec:gompertz:pmcmc}

To carry out Bayesian inference we need to specify a prior distribution on unknown parameters.
The \code{pomp} constructor function provides the \code{rprior} and \code{dprior} arguments, which can be filled with functions that simulate from and evaluate the prior density, respectively.
%% Although POMP models frequently have strong nonlinear dependencies between parameters, it is common practice to specify independent prior distributions for each parameter.
Methods based on random walk Metropolis-Hastings require evaluation of the prior density (\code{dprior}), but not simulation (\code{rprior}), so we specify \code{dprior} for the Gompertz model as follows.
<<pmcmc-comments,include=FALSE>>=
##' ## Particle MCMC
##' We'll need a prior density function:
<<gompertz-dprior1>>=
hyperparams <- list(
  min = coef(gomp)/10,
  max = coef(gomp)*10
)
@
<<gompertz-dprior2>>=
gompertz.dprior <- function (r, K, sigma, tau, X_0, ..., log) {
  f <- sum(dunif(c(r, K, sigma, tau, X_0),
    min = hyperparams$min, max = hyperparams$max,log = TRUE))
  if (log) f else exp(f)
}
@
The PMCMC algorithm described in \cref{sec:pmcmc} can then be applied to draw a sample from the posterior.
Recall that, for each parameter proposal, PMCMC pays the full price of a particle filtering operation in order to obtain the Metropolis-Hastings acceptance probability.
For the same price, iterated filtering obtains, in addition, an estimate of the derivative and a probable improvement of the parameters.
For this reason, PMCMC is relatively inefficient at traversing parameter space.
When Bayesian inference is the goal, it is therefore advisable to first locate a neighborhood of the MLE using, for example, iterated filtering.
PMCMC can then be initialized in this neighborhood to sample from the posterior distribution.
The following adopts this approach, running 5 independent PMCMC chains using a multivariate normal random walk proposal (with diagonal variance-covariance matrix, see \code{?mvn.diag.rw}).
<<pmcmc-inner,eval=FALSE,purl=FALSE,echo=FALSE>>=
pmcmc(gomp, dprior = gompertz.dprior, params = theta.mif,
      Nmcmc = 40000, Np = 100,
      proposal = mvn_diag_rw(c(r = 0.01, sigma = 0.01, tau = 0.01)))
<<pmcmc-demo,eval=FALSE,purl=FALSE,echo=TRUE>>=
pmcmc1 <- foreach(i = 1:5, .combine = c) %dopar% {
  <<pmcmc-inner>>
}
<<pmcmc-eval,echo=FALSE,results="hide",cache=FALSE>>=
##' Do the PMCMC calculations.
##' Again, delete 'pmcmc.rda' to reproduce the computations.
##' This took about 16 min on my 16-core Intel Xeon 2.90GHz machine
##' with 32GB of memory.
library(pomp)
library(coda)

stew(file="pmcmc.rda",seed=334388458L,kind="L'Ecuyer",{

  tic <- Sys.time()
  library(doParallel)
  library(foreach)
  registerDoParallel()

  pmcmc1 <- foreach(
    i=1:5,
    .inorder=FALSE,
    .packages="pomp",
    .combine=c,
    .options.multicore=list(set.seed=TRUE)
  ) %dopar%
  {
    <<pmcmc-inner>>
  }

toc <- Sys.time()
pmcmcTime <- toc-tic

pmcmc.traces <- traces(pmcmc1,  c("r", "sigma", "tau"))
pmcmc.traces <- window(pmcmc.traces,start=20001,thin=40)
ess.pmcmc <- effectiveSize(pmcmc.traces)
rm(pmcmc1,tic,toc)
})
<<pmcmc-diagnostics,results="hide",fig.show="hide",echo=FALSE,eval=FALSE,purl=FALSE>>=
gelman.diag(pmcmc.traces)
gelman.plot(pmcmc.traces)
autocorr.plot(pmcmc.traces[[1]])
hist(rle(unlist(pmcmc.traces[,"r"]))$length)
@

\begin{figure}[t!]
<<pmcmc-plot,echo=FALSE,eval=TRUE,results="hide",cache=TRUE>>=
##' Plot the traces and densities.
op <- par(mar=c(4,3.5,0,1),mfcol=c(3,2),mgp=c(2.5,1,0),cex.axis=1.5,cex.lab=2)
traceplot(pmcmc.traces[,"r"],smooth=TRUE,xlab="",ylab=expression(r),lty=1)
traceplot(pmcmc.traces[,"sigma"],smooth=TRUE,xlab="",ylab=expression(sigma),lty=1)
traceplot(pmcmc.traces[,"tau"],smooth=TRUE,xlab="PMCMC iteration",ylab=expression(tau),lty=1)
densplot(pmcmc.traces[,"r"],show.obs=FALSE,xlab="",main="")
mtext(side=1,line=2,text=expression(r))
abline(v=coef(gomp,"r"))
densplot(pmcmc.traces[,"sigma"],show.obs=FALSE,xlab="",main="")
mtext(side=1,line=2,text=expression(sigma))
abline(v=coef(gomp,"sigma"))
densplot(pmcmc.traces[,"tau"],show.obs=FALSE,xlab=expression(tau),main="")
abline(v=coef(gomp,"tau"))
par(op)
@
\caption{
  Diagnostic plots for the PMCMC algorithm.
  The trace plots in the left column show the evolution of $\Sexpr{length(pmcmc.traces)}$ independent MCMC chains after a burn-in period of length $\Sexpr{start(pmcmc.traces)-1}$.
  Kernel density estimates of the marginal posterior distributions are shown in the right column.
  The effective sample size of the $\Sexpr{length(pmcmc.traces)}$ MCMC chains combined is lowest for the $r$ variable, being equal to $\Sexpr{signif(min(ess.pmcmc),2)}$:
  the use of $\Sexpr{end(pmcmc.traces)-1}$ proposal steps in this case is a modest number.
  The density plots at right show the estimated marginal posterior distributions.
  The vertical line corresponds to the true value of each parameter.
  \label{fig:pmcmc-plot}
}
\end{figure}

Comparison with the analysis of \cref{sec:gompertz:mif} reinforces the observation of \citet{Bhadra2010} that PMCMC can require orders of magnitude more computation than iterated filtering.
Iterated filtering may have to be repeated multiple times while computing profile likelihood plots, whereas one successful run of PMCMC is sufficient to obtain all required posterior inferences.
However, in practice, multiple runs from a range of starting points is always good practice since convergence cannot be reliably assessed on the basis of a single chain.
To verify the convergence of the approach or to compare the performance with other approaches, we can use diagnostic plots produced by the \code{plot} methods (see \cref{fig:pmcmc-plot}).


\subsection{A second example: The Ricker model}
\label{sec:ricker:setup}

In \cref{sec:ricker:probe.match}, we will illustrate probe matching (see \cref{sec:probe}) using a stochastic version of the Ricker map \citep{Ricker1954}.
We switch models to allow direct comparison with \citet{Wood2010}, whose synthetic likelihood computations are reproduced below.
In particular, the results of \cref{sec:ricker:probe.match} demonstrate frequentist inference using synthetic likelihood and also show that the full likelihood is both numerically tractable and reasonably well behaved, contrary to the claim of \citet{Wood2010}.
We will also take the opportunity to demonstrate features of \pkg{pomp} that allow acceleration of model codes through the use of \proglang{R}'s facilities for compiling and dynamically linking \proglang{C} code.

The Ricker model is another discrete-time model for the size of a population.
The population size, $N_t$, at time $t$ is postulated to obey
\begin{equation}\label{eq:ricker-process}
  N_{t+1}=r\,N_t\,\exp(-N_t+e_t),\qquad e_t\!\sim\!\normal\left(0,\sigma^2\right).
\end{equation}
In addition, we assume that measurements, $Y_t$, of $N_t$ are themselves noisy, according to
\begin{equation}\label{eq:ricker-measure}
  Y_t\!\sim\!\mathrm{Poisson}(\phi\,N_t),
\end{equation}
where $\phi$ is a scaling parameter.
As before, we will need to implement the model's state-process simulator (\code{rprocess}).
We have the option of writing these functions in \proglang{R}, as we did with the Gompertz model.
However, we can realize manyfold speed-ups by writing these in \proglang{C}.
In particular, \pkg{pomp} allows us to write snippets of \proglang{C} code that it assembles, compiles, and dynamically links into a running \proglang{R} session.
To begin the process, we will write snippets for the \code{rprocess}, \code{rmeasure}, and \code{dmeasure} components.
<<ricker-comments,include=FALSE>>=
##' ## Second example: stochastic Ricker map.
##' Some C snippets defining the process model simulator
<<ricker-map-defn>>=
ricker.rproc <- "
   e = rnorm(0, sigma);
   N = r * N * exp(-c * N + e);"
ricker.rmeas <- "
   y = rpois(phi * N);"
ricker.dmeas <- "
   lik = dpois(y, phi * N, give_log);"
@
Note that, in this implementation, both $N$ and $e$ are state variables.
The logical flag \code{give_log} requests the likelihood when \code{FALSE}, the log likelihood when \code{TRUE}.
Notice that, in these snippets, we never declare the variables;
\pkg{pomp} will construct the appropriate declarations automatically.

In a similar fashion, we can add transformations of the parameters to enforce constraints.
<<ricker-trans>>=
log.trans <- "
   T_r = log(r);
   T_sigma = log(sigma);
   T_phi = log(phi);"
exp.trans <- "
   r = exp(T_r);
   sigma = exp(T_sigma);
   phi = exp(T_phi);"
@
Note that in the foregoing \proglang{C} snippets, the prefix \code{T} designates the transformed version of the parameter.
A full set of rules for using \code{Csnippet}s, including illustrative examples, is given in the package help system (\code{?Csnippet}).

Now we can construct a class-\class{pomp} object as before and fill it with simulated data:
<<ricker-pomp,eval=TRUE,tidy=FALSE>>=
rick <- simulate(times = seq(0,50,by=1), t0 = 0, seed=73691676L,
  rprocess = discrete_time(step.fun = Csnippet(ricker.rproc), delta.t = 1),
  rmeasure = Csnippet(ricker.rmeas), dmeasure = Csnippet(ricker.dmeas),
  partrans = parameter_trans(toEst = Csnippet(log.trans),
    fromEst = Csnippet(exp.trans)), paramnames = c("r", "c", "sigma",
      "phi", "N_0", "e_0"), statenames = c("N", "e"), obsnames="y",
  params = c(r = exp(3.8), sigma = 0.3, phi = 10, c=1, N_0 = 7, e_0 = 0))
@

\subsection{Feature-based synthetic likelihood maximization}
\label{sec:ricker:probe.match}

In \pkg{pomp}, probes are simply functions that can be applied to an array of real or simulated data to yield a scalar or vector quantity.
Several functions that create useful probes are included with the package, including those recommended by \citet{Wood2010}.
In this illustration, we will make use of these probes:
\code{probe.marginal}, \code{probe.acf}, and \code{probe.nlar}.
\code{probe.marginal} regresses the data against a sample from a reference distribution;
the probe's values are those of the regression coefficients.
\code{probe.acf} computes the auto-correlation or auto-covariance of the data at specified lags.
\code{probe.nlar} fits a simple nonlinear (polynomial) autoregressive model to the data;
again, the coefficients of the fitted model are the probe's values.
We construct a list of probes:
<<probe-comments,include=FALSE>>=
##' ## Probe-matching via synthetic likelihood

##' We'll need a list of summary statistics ('probes').
##' The following are among those recommended by Wood (2010).
<<probe-list>>=
plist <- list(probe_marginal("y", ref = obs(rick), transform = sqrt),
              probe_acf("y", lags = c(0, 1, 2, 3, 4), transform = sqrt),
              probe_nlar("y", lags = c(1, 1, 1, 2), powers = c(1, 2, 3, 1),
                         transform = sqrt))
@
Each element of \code{plist} is a function of a single argument.
Each of these functions can be applied to the data in \code{rick} and to simulated data sets.
Calling \pkg{pomp}'s function \code{probe} results in the application of these functions to the data, and to each of some large number, \code{nsim}, of simulated data sets, and finally to a comparison of the two.
[Note that probe functions may be vector-valued, so a single probe taking values in $\R^k$ formally corresponds to a collection of $k$ probe functions in the terminology of \cref{sec:probe}.]
Here, we will apply \code{probe} to the Ricker model at the true parameters and at a wild guess.
<<first-probe-comment,include=FALSE>>=
##' Compute the probes at true parameters and arbitrary "guess".
<<first-probe,eval=TRUE,echo=TRUE,cache=TRUE>>=
pb.truth <- probe(rick,probes=plist,nsim=1000,seed=803306074L)
guess <- c(r=40,sigma=0.5,phi=12,N_0=7,e_0=0,c=1)
pb.guess <- probe(rick,params=guess,probes=plist,nsim=1000,seed=803306074L)
@
Results summaries and diagnostic plots showing the model-data agreement and correlations among the probes can be obtained by
<<first-probe-plot,eval=FALSE,purl=FALSE>>=
summary(pb.truth)
summary(pb.guess)
plot(pb.truth)
plot(pb.guess)
@

\begin{figure}[t!]
<<ricker-probe-plot,echo=FALSE,cache=TRUE,results="hide",dpi=600,dev.args=list(bg="transparent",pointsize=9),fig.height=4,fig.width=4>>=
##' An example of 'plot' applied to a 'probed.pomp' object.
pb <- probe(
  rick,
  probes=list(
    probe_marginal("y",ref=obs(rick),transform=sqrt,order=2),
    probe_acf("y",lags=c(0,3),transform=sqrt),
    mean=probe_mean("y",transform=sqrt)
  ),
  nsim=1000,
  seed=803306074L
)
plot(pb)
@
\caption{
  Results of \code{plot} on a \class{probed.pomp} object.
  Above the diagonal, the pairwise scatterplots show the values of the probes on each of the 1000 data sets.
  The red lines show the values of each of the probes on the data.
  The panels along the diagonal show the distributions of the probes on the simulated data, together with their values on the data and two-sided $p$~values.
  The numbers below the diagonal are the Pearson correlations between the corresponding pairs of probes.
}
\label{fig:ricker-probe-plot}
\end{figure}

An example of a diagnostic plot (using a smaller set of probes) is shown in \cref{fig:ricker-probe-plot}.
Among the quantities returned by \code{summary} is the synthetic likelihood (\cref{alg:probe}).
One can attempt to identify parameters that maximize this quantity;
this procedure is referred to in \pkg{pomp} as ``probe matching''.
Let us now attempt to fit the Ricker model to the data using probe-matching.
<<ricker-probe-match-calc,eval=FALSE,purl=FALSE,results="markup">>=
pfun <- probe_objfun(pb.guess,est=c("r","sigma","phi"),seed=803306074L)
library("subplex")
pm <- subplex(fn=pfun,
  par = coef(pb.guess,c("r","sigma","phi"),transform=TRUE),
  control=list(reltol=1e-10))
pfun(pm$par)
@
<<ricker-probe.match-eval,echo=FALSE,eval=TRUE,results="hide",cache=FALSE>>=
##' Now we'll do some probe-matching.
##' Again, delete the binary file to cause the computations to be reproduced.
##' These calculations took less than 20 sec on my Intel Xeon 2.90GHz workstation.
stew(file="ricker-probe-match.rda",{
  <<ricker-probe-match-calc>>
})
@
This code runs the \code{subplex} optimizer \citep{Rowan1990,subplex} from the starting parameters \code{guess} in an attempt to maximize the synthetic likelihood based on the probes in \code{plist}.
Both the starting parameters and the list of probes are stored internally in \code{pb.guess}, which is why we need not specify them explicitly here.
\pkg{pomp} allows full flexibility in the choice of the optimization algorithm:
the objective function constructed by \code{probe\_objfun} is suitable for use with essentially arbitrary optimization routines.

To put the synthetic likelihood approach into context, let us compare the results of estimating the Ricker model parameters using probe-matching and using iterated filtering (IF), which is based on the likelihood.
The following code runs 600 IF iterations starting at \code{guess}:
<<ricker-mif-calc,eval=FALSE,purl=FALSE>>=
mf <- mif2(pb.guess,Nmif=100,Np=1000,cooling.fraction.50 = 0.08,
  rw.sd = rw_sd(r = 0.1, sigma = 0.1, phi = 0.1))
mf <- continue(mf, Nmif = 500)
<<ricker-mif-eval,echo=FALSE,eval=TRUE,cache=FALSE,results="hide">>=
##' Now, for comparison, run 600 'mif' iterations.
##' These serial calculations took about 3 minutes.
stew(file="ricker-mif.rda",seed=718086921L,{
  <<ricker-mif-calc>>
})
@
\Cref{tab:ricker-comparison} compares parameters, Monte Carlo likelihoods ($\loglikMC$), and synthetic likelihoods ($\synloglikMC$, based on the probes in \code{plist}) at each of
\begin{inparaenum}[(a)]
\item the guess,
\item the truth,
\item the MLE from \code{mif}, and
\item the maximum synthetic likelihood estimate (MSLE) obtained by optimizing the objective function returned by \code{probe\_objfun}.
\end{inparaenum}
These results demonstrate that it is possible, and indeed not difficult, to maximize the likelihood for this model, contrary to the claim of \citet{Wood2010}.
Since synthetic likelihood discards some of the information in the data, it is not surprising that \cref{tab:ricker-comparison} also shows the statistical inefficiency of the maximum synthetic likelihood relative to that of the likelihood.

<<ricker-comparison,eval=TRUE,echo=FALSE,cache=FALSE>>=
##' The comparison, in terms of approximate likelihood and synthetic likelihood.
##' Not a very expensive set of computations.
stew(file="ricker-comparison.rda",{
  library(tidyverse)
  library(foreach)
  library(doParallel)
  library(doRNG)
  registerDoParallel()
  registerDoRNG(1431015321)

  bind_rows(Guess=guess,Truth=coef(rick),
    MLE=coef(mf),MSLE=coef(pfun),
    .id="pt") -> comp

  foreach (theta=iter(expand_grid(comp,rep=1:10),"row"),
    .combine=rbind) %dopar% {
    logLik(pfilter(rick,params=theta[-1],Np=10000)) -> pf
    logLik(probe(rick,params=theta[-1],nsim=10000,probes=plist)) -> pb
    cbind(theta,pf=pf,pb=pb)
    } |>
    group_by(pt,r,sigma,phi,c,N_0,e_0) |>
    summarize(
      loglik=logmeanexp(pf)[1],
      loglik.se=logmeanexp(pf,se=TRUE)[2],
      logsynlik=logmeanexp(pb)[1],
      logsynlik.se=logmeanexp(pb,se=TRUE)[2]
    ) |>
    ungroup() |>
    column_to_rownames("pt") |>
    select(-c,-N_0,-e_0) -> comp
  
})
@
\begin{table}[t!]
  \begin{center}
<<ricker-comparison-show,echo=FALSE,results="asis">>=
library(xtable)
colnames(comp) <- c("$r$","$\\sigma$","$\\phi$",
                    "$\\loglikMC$","s.e.($\\loglikMC$)",
                    "$\\synloglikMC$","s.e.($\\synloglikMC$)")
print(xtable(comp[c("Guess","Truth","MLE","MSLE"),],
  align="r|ccccccc",digits=c(0,1,3,1,1,2,1,2)))
@
  \end{center}
  \caption{\label{tab:ricker-comparison}
    Parameter estimation by means of maximum synthetic likelihood (\cref{alg:probe}) vs.\ by means of maximum likelihood via iterated filtering (\cref{alg:mif}).
    The row labeled ``guess'' contains the point at which both algorithms were initialized.
    That labeled ``truth'' contains the true parameter value, i.e., that at which the data were generated.
    The rows labeled ``MLE'' and ``MSLE'' show the estimates obtained using iterated filtering and maximum synthetic likelihood, respectively.
    Parameters $r$, $\sigma$, and $\phi$ were estimated; all others were held at their true values.
    The columns labeled $\loglikMC$ and $\synloglikMC$ are the Monte Carlo estimates of the log likelihood and the log synthetic likelihood, respectively;
    their Monte Carlo standard errors are also shown.
    While likelihood maximization results in an estimate for which both $\loglikMC$ and $\synloglikMC$ exceed their values at the truth,
    the value of $\loglikMC$ at the MSLE is smaller than at the truth, an indication of the relative statistical inefficiency of maximum synthetic likelihood.
  }
\end{table}

\subsection{Bayesian feature matching via ABC}
\label{sec:gompertz:abc}

Whereas the synthetic likelihood approach carries out many simulations for each likelihood estimation, ABC (as described in \cref{sec:abc}) uses only one.
Each iteration of ABC is therefore much quicker, essentially corresponding to the cost of SMC with a single particle or the synthetic likelihood approach with a single simulation.
A consequence of this is that ABC cannot determine a good relative scaling of the features within each likelihood evaluation and this must be supplied in advance.
One can imagine an adaptive version of ABC which modifies the scaling during the course of the algorithm, but here we do a preliminary calculation to accomplish this.
We return to the Gompertz model to faciliate comparison between ABC and PMCMC.
<<abc-load,eval=FALSE,purl=FALSE,echo=FALSE>>=
plist <- list(probe_mean(var = "Y", transform = sqrt),
              probe_acf("Y", lags = c(0, 5, 10, 20)),
              probe_marginal("Y", ref = obs(gomp)))
psim <- probe(gomp, probes = plist, nsim = 500)
scale.dat <- apply(psim@simvals, 2, sd)
@
<<abc-inner,eval=FALSE,purl=FALSE,echo=FALSE>>=
abc(pomp(gomp, dprior = gompertz.dprior), Nabc = 4e6,
    probes = plist, epsilon = 2, scale = scale.dat,
    proposal = mvn_diag_rw(c(r = 0.01, sigma = 0.01, tau = 0.01)))
@
<<abc-demo,eval=FALSE,purl=FALSE,tidy=FALSE>>=
<<abc-load>>
abc1 <- foreach(i = 1:5, .combine = c) %dopar% {
  <<abc-inner>>
}
<<abc-eval,include=FALSE,purl=TRUE,cache=FALSE>>=
library("pomp")
##' ## Approximate Bayesian computation
##' We'll go back to working with the Gompertz model.

##' Select a set of summary statistics ('probes').
##' Use simulations to estimate the scale of variation of these probes.
<<abc-load>>

##' Do 5 long ABC chains in parallel.
##' These computations took about 30 min on my
##' 16-core Intel Xeon 2.90GHz machine with 32MB of RAM.
stew(file="abc.rda",seed=334388458L,kind="L'Ecuyer",{

  tic <- Sys.time()
  library(doParallel)
  library(foreach)
  registerDoParallel()

  abc1 <- foreach(
    i=1:5,
    .inorder=FALSE,
    .packages="pomp",
    .combine=c,
    .options.multicore=list(set.seed=TRUE)
  ) %dopar% {
    <<abc-inner>>
  }

toc <- Sys.time()
abcTime <- toc-tic

abc.traces <- traces(abc1,c("r","sigma","tau"))
abc.traces <- window(abc.traces,start=2000001,thin=400)
ess.abc <- effectiveSize(abc.traces)
rm(abc1,tic,toc)
})

<<abc-diagnostics,results="hide",fig.show="hide",echo=FALSE,eval=FALSE,purl=FALSE>>=
gelman.diag(abc.traces)
gelman.plot(abc.traces)
autocorr.plot(abc.traces[[1]])
hist(rle(unlist(abc.traces[,"r"]))$length)
@

\begin{figure}[t!]
\begin{center}
<<abc-pmmc-compare,echo=FALSE,fig.width=7,fig.height=3,cache=TRUE>>=
library("tidyverse")
library("grid")
##' Make density plots comparing posteriors from 'abc' and 'pmcmc'.
bind_rows(
  pmcmc=pmcmc.traces |> lapply(as.data.frame) |>
    lapply(rownames_to_column,"iteration") |> bind_rows(.id="chain"),
  abc=abc.traces |> lapply(as.data.frame) |>
    lapply(rownames_to_column,"iteration") |> bind_rows(.id="chain"),
  .id="method"
) |>
  gather(variable,value,-method,-chain,-iteration) |>
  mutate(
    method=ordered(method,levels=c("pmcmc","abc")),
    iteration=as.integer(iteration),
    variable=c(r="log[10]~r",sigma="log[10]~sigma",tau="log[10]~tau")[variable],
    log.value=log10(value)
  ) -> traces

coef(gomp,c("r","sigma","tau")) |> as.list() |> as.data.frame() |>
  gather(variable,value) |>
  mutate(
    variable=c(r="log[10]~r",sigma="log[10]~sigma",tau="log[10]~tau")[variable],
    log.value=log10(value)
  ) -> truth

traces |>
  ggplot(mapping=aes(x=log.value,linetype=method))+
  geom_density(adjust=5)+
  geom_vline(data=truth,mapping=aes(xintercept=log.value))+
  scale_linetype_manual(values=c(abc=2,pmcmc=1))+
  facet_grid(~variable,scales="free_x",labeller=label_parsed)+
  labs(x="",y="",linetype="")+
  theme_classic()+
  theme(legend.position=c(0.35,0.7),
        strip.background=element_rect(fill=NA,color=NA),
        strip.text=element_text(size=12),
        panel.spacing=unit(4,"mm"))
@
\end{center}
\caption{
  Marginal posterior distributions using full information via \code{pmcmc} (solid line) and partial information via \code{abc} (dashed line).
  Kernel density estimates are shown for the posterior marginal densities of the three estimated paramters.
  The vertical lines indicate the true values of each parameter.
}
\label{fig:abc:pmcmc:compare}
\end{figure}

The effective sample size of the ABC chains is lowest for the $r$ parameter (as was the case for PMCMC) and is $\Sexpr{signif(min(ess.abc),2)}$, as compared to $\Sexpr{signif(min(ess.pmcmc),2)}$ for \code{pmcmc} in \cref{sec:gompertz:pmcmc}.
The total computational effort allocated to \code{abc} here matches that for \code{pmcmc} since \code{pmcmc} used 100 particles for each likelihood evaluation but is awarded 100 times fewer Metropolis-Hastings steps.
In this example, we conclude that \code{abc} mixes somewhat more rapidly (as measured by total computational effort) than \code{pmcmc}.
\Cref{fig:abc:pmcmc:compare} investigates the statistical efficiency of \code{abc} on this example.
We see that \code{abc} gives rise to somewhat broader posterior distributions than the full-information posteriors from \code{pmcmc}.
As in all numerical studies of this kind, one cannot readily generalize from one particular example: even for this specific model and dataset, the conclusions might be sensitive to the algorithmic settings.
However, one should be aware of the possibility of losing substantial amounts of information even when the features are based on reasoned scientific argument \citep{Shrestha2011,Ionides2011b}.
Despite this loss of statistical efficiency, points~B\ref{whyFeature1}--B\ref{whyFeature5} of \cref{sec:probe} identify situations in which ABC may be the only practical method available for Bayesian inference.


\subsection{Parameter estimation by simulated quasi-likelihood}
\label{sec:gompertz:nlf}

With the \pkg{pomp} package, it is fairly easy to try a quick comparison to see how \code{nlf} (\cref{sec:nlf}) compares with \code{mif} (\cref{sec:mif}) on the Gompertz model.
Carrying out a simulation study with a correctly specified POMP model is appropriate for assessing computational and statistical efficiency, but does not contribute to the debate on the role of two-step prediction criteria to fit misspecified models \citep{Xia2011,Ionides2011b}.
The \code{nlf} implementation we will use to compare to the \code{mif} call from \cref{sec:gompertz:mif} is
<<first-nlf,eval=FALSE,purl=FALSE>>=
nlf1 <- nlf_objfun(gomp, ti=100, tf=4000, lags = c(2, 3),
  params = c(r = 1, K = 2, sigma = 0.5, tau = 0.5, X.0 = 1),
  est = c("r", "sigma", "tau"))
subplex(par = c(r=0.2, sigma=0.15, tau=0.08), fn=nlf1, control=list(reltol=1e-4)) -> nlf1_out
nlf1(nlf1_out$par)
@
where the first argument is the class-\class{pomp} object,
\code{params} is a vector containing model parameters at which \code{nlf}'s search will begin,
\code{est} contains the names of parameters \code{nlf} will estimate, and
\code{lags} specifies which past values are to be used in the autoregressive model.
The \code{transform = TRUE} setting causes the optimization to be performed on the transformed scale, as in \cref{sec:gompertz:mif}.
In the call above \code{lags = c(2, 3)} specifies that the autoregressive model predicts each observation, $y_t$ using $y_{t-2}$ and $y_{t-3}$, as recommended by \citet{Kendall2005}.
The quasi-likelihood is optimized numerically, so the reliability of the optimization should be assessed by doing multiple fits with different starting parameter values:
the results of a small experiment (not shown) indicate that, on these simulated data, repeated optimization is not needed.
\code{nlf} defaults to optimization by the subplex method \citep{Rowan1990,subplex}, though all optimization methods provided by \code{optim} are available as well.
\code{nasymp} sets the length of the simulation on which the quasi-likelihood is based;
larger values will give less variable parameter estimates, but will slow down the fitting process.
The computational demand of \code{nlf} is dominated by the time required to generate the model simulations, so efficient coding of \code{rprocess} is worthwhile.

<<nlf-mif-comp-setup,eval=TRUE,echo=FALSE,results="hide">>=
##' ## Nonlinear Forecasting

##' Here, we'll do a comparison of NLF with MIF.
set.seed(4897341L)

##' Number of replicates:
R <- 10

##' Parameters to estimate:
estpars <- c("r","sigma","tau")
gompList <- simulate(gomp,nsim=R)

<<nlf-mif-compare-eval,echo=FALSE,eval=TRUE,results="hide">>=
##' The following took 47 sec on my workstation.
stew(file="nlf-mif-compare.rda",seed=816326853L,kind="L'Ecuyer",{
  library(doParallel)
  library(foreach)
  registerDoParallel()

  tic <- Sys.time()
  cmp1 <- foreach(
    gomp=gompList,
    .inorder=FALSE,.packages=c("pomp","subplex"),.combine=rbind,
    .options.multicore=list(set.seed=TRUE)
  ) %dopar% {
    true.lik <- pfilter(gomp,Np=1000)
    true.nlf <- nlf_objfun(gomp,
      ti=100, tf=2000,
      lags=c(2,3))
    true.sql <- true.nlf(coef(gomp))

  ## start at the truth:
  theta.guess <- coef(gomp)

  tic <- Sys.time()
  mif1 <- mif2(gomp,Nmif=100,params=theta.guess,
    rw.sd=rw_sd(r=0.02,sigma=0.02,tau=0.05),Np=1000,
    cooling.type="geometric",cooling.fraction=0.5)
  mif.lik <- pfilter(mif1,Np=10000)
  toc <- Sys.time()
  mif.time <- toc-tic
  units(mif.time) <- "secs"
  mif.nlf <- nlf_objfun(mif1, ti=100, tf=4000,
      lags=c(2,3))
  mif.sql <- mif.nlf(coef(mif1))

  tic <- Sys.time()
  nlfobj <- nlf_objfun(gomp,
      ti=100, tf=4000,
      lags=c(2,3))
  nlf_out <- subplex(par = coef(gomp, estpars, transform=TRUE), fn=nlfobj, control=list(reltol=1e-8))
  toc <- Sys.time()
  nlf.time <- toc-tic
  units(nlf.time) <- "secs"
  nlf.lik <- pfilter(pomp(gomp, params=coef(nlfobj)),Np=1000)
  nlf.sql <- nlfobj(coef(nlfobj))

  c(
    trueLik=logLik(true.lik),
    trueSQL=-true.sql,
    mifLik=logLik(mif.lik),
    mifSQL=-mif.sql,
    nlfLik=logLik(nlf.lik),
    nlfSQL=-nlf.sql,
    mifTime=mif.time,
    nlfTime=nlf.time
  )
}
toc <- Sys.time()
nlf.mif.time <- toc-tic
cmp1 <- as.data.frame(cmp1)
})
@

\begin{figure}[t!]
  \begin{center}
<<nlf-mif-plot,echo=FALSE,fig.width=8,fig.height=3.5>>=
##' Plot the results.
library("ggplot2")
library("grid")

plA <- cmp1 |>
  ggplot(mapping=aes(y=mifLik-trueLik,x=nlfLik-trueLik))+
  geom_point()+
  geom_abline(slope=1,intercept=0,linetype=3)+
  geom_hline(yintercept=0,linetype=3)+
  geom_vline(xintercept=0,linetype=3)+
  expand_limits(x=c(-1,1),y=c(-1,1))+
  labs(y=expression(hat("\u2113")(hat(theta))-hat("\u2113")(theta)),
       x=expression(hat("\u2113")(tilde(theta))-hat("\u2113")(theta)))+
  theme_classic()

plB <- cmp1 |>
  ggplot(mapping=aes(y=mifSQL-trueSQL,x=nlfSQL-trueSQL))+
  geom_point()+
  geom_abline(slope=1,intercept=0,linetype=3)+
  geom_hline(yintercept=0,linetype=3)+
  geom_vline(xintercept=0,linetype=3)+
  expand_limits(x=c(-1,1),y=c(-1,1))+
  labs(y=expression(hat("\u2113")[Q](hat(theta))-hat("\u2113")[Q](theta)),
       x=expression(hat("\u2113")[Q](tilde(theta))-hat("\u2113")[Q](theta)))+
  theme_classic()

grid.newpage()
pushViewport(viewport(layout=grid.layout(1,2)))
print(plA,vp=viewport(layout.pos.row=1,layout.pos.col=1))
print(plB,vp=viewport(layout.pos.row=1,layout.pos.col=2))
grid.text("A",x=unit(0.1,"npc"),y=unit(1,"npc"),
          vp=viewport(layout.pos.row=1,layout.pos.col=1),
          hjust=0.5,vjust=1,
          gp=gpar(fontsize=16,fontface="bold"))
grid.text("B",x=unit(0.1,"npc"),y=unit(1,"npc"),
          vp=viewport(layout.pos.row=1,layout.pos.col=2),
          hjust=0.5,vjust=1,
          gp=gpar(fontsize=16,fontface="bold"))
popViewport()
@
  \end{center}
  \caption{
    Comparison of \code{mif} and \code{nlf} for $\Sexpr{nrow(cmp1)}$ simulated datasets using two criteria.
    In both plots, the maximum likelihood estimate (MLE), $\hat\theta$, obtained using iterated filtering is compared with the maximum simulated quasi-likelihood (MSQL) estimate, $\tilde\theta$, obtained using nonlinear forecasting.
    (A) Improvement in estimated log likelihood, $\loglikMC$, at the point estimate over that at the true parameter value, $\theta$.
    (B) Improvement in simulated log quasi-likelihood $\loglikMC_Q$, at the point estimate over that at the true parameter value, $\theta$.
    In both panels, the diagonal line is the 1--1 line.
    \label{fig:mif:nlf:compare}
  }
\end{figure}

\Cref{fig:mif:nlf:compare} compares the true parameter, $\theta$, with the maximum likelihood estimate (MLE), $\hat\theta$, from \code{mif} and the maximized simulated quasi-likelihood (MSQL), $\tilde\theta$, from \code{nlf}.
\Cref{fig:mif:nlf:compare}A plots  $\loglikMC(\hat\theta)-\loglikMC(\theta)$ against $\loglikMC(\tilde\theta)-\loglikMC(\theta)$, showing that the MSQL estimate can fall many units of log likelihood short of the MLE.
\Cref{fig:mif:nlf:compare}B plots $\loglikMC_Q(\hat\theta)-\loglikMC_Q(\theta)$ against $\loglikMC_Q(\tilde\theta)-\loglikMC_Q(\theta)$, showing that likelihood-based inference is almost as good as \code{nlf} at optimizing the simulated quasi-likelihood criterion which \code{nlf} targets.
\Cref{fig:mif:nlf:compare} suggests that the MSQL approach may be inefficient, since it can give estimates with poor behavior according to the statistically efficient criterion of likelihood.
Another possibility is that this particular implementation of \code{nlf} was unfortunate.
Each \code{mif} optimization took $\Sexpr{format(round(mean(cmp1$mifTime),1))}$~sec to run, compared to $\Sexpr{format(round(mean(cmp1$nlfTime),1))}$~sec for \code{nlf}, and it is possible that extra computer time or other algorithmic adjustments could substantially improve either or both estimators.
It is hard to ensure a fair comparison between methods, and in practice there is little substitute for some experimentation with different methods and algorithmic settings on a problem of interest.
If the motivation for using NLF is preference for 2-step prediction in place of the likelihood, a comparison with SMC-based likelihood evaluation and maximization is useful to inform the user of the consequences of that preference.


\section{A more complex example: Epidemics in continuous time}
\label{sec:EpidemicModel}

\begin{figure}
  \begin{center}
    \resizebox{0.5\textwidth}{!}{
      \Large
      \setlength{\unitlength}{5pt}
	\begin{picture}(44,20)(-5,-4)
	  \thicklines
	  \put(0,0){\framebox(6,6){S}}
	  \put(16,0){\framebox(6,6){I}}
	  \put(32,0){\framebox(6,6){R}}
	  \put(-4,3){\vector(1,0){4}}
	  \put(-3.7,3.9){$\mu$}
	  \put(6,3){\vector(1,0){10}}
	  \put(9,0){$\lambda(t)$}
	  \put(11,4){\vector(0,1){5}}
	  \put(11.7,6){$\rho$}
	  \put(11,11.5){\circle{5}}
	  \put(9.8,10.6){{$C$}}
	  \put(3,-0.2){\vector(0,-1){4}}
	  \put(4,-3){$\mu$}
	  \put(19,-0.2){\vector(0,-1){4}}
	  \put(20,-3){$\mu$}
	  \put(22,3){\vector(1,0){10}}
	  \put(26,3.9){$\gamma$}
	  \put(35,-0.2){\vector(0,-1){4}}
	  \put(36,-3){$\mu$}
	\end{picture}
    }
  \end{center}
  \caption{
    Diagram of the SIR epidemic model.
    The host population is divided into three classes according to infection status:
    S, susceptible hosts;
    I, infected (and infectious) hosts;
    R, recovered and immune hosts.
    Births result in new susceptibles and all individuals have a common death rate $\mu$.
    Since the birth rate equals the death rate, the expected population size, $P=S+I+R$, remains constant.
    The S$\to$I rate, $\lambda$, called the \emph{force of infection}, depends on the number of infectious individuals according to $\lambda(t)={\beta\,I}/{N}$.
    The I$\to$R, or recovery, rate is $\gamma$.
    The case reports, $C$, result from a process by which new infections are recorded with probability $\rho$.
    Since diagnosed cases are treated with bed-rest and hence removed, infections are counted upon transition to R.
  }
  \label{fig:SIR}
\end{figure}

\subsection{A stochastic, seasonal SIR model}

A mainstay of theoretical epidemiology, the SIR model describes the progress of a contagious, immunizing infection through a population of hosts \citep{Kermack1927,Anderson1991,Keeling2008a}.
The hosts are divided into three classes, according to their status vis-{\`a}-vis the infection (\cref{fig:SIR}).
The susceptible class (S) contains those that have not yet been infected and are thereby still susceptible to it;
the infected class (I) comprises those who are currently infected and, by assumption, infectious;
the removed class (R) includes those who are recovered or quarantined as a result of the infection.
Individuals in R are assumed to be immune against reinfection.
We let $S(t)$, $I(t)$, and $R(t)$ represent the numbers of individuals within the respective classes at time $t$.

It is natural to formulate this model as a continuous-time Markov process.
In this process, the numbers of individuals within each class change through time in whole-number increments as discrete births, deaths, and passages between compartments occur.
Let $\cp{A}{B}$ be the stochastic counting process whose value at time $t$ is the number of individuals that have passed from compartment $A$ to compartment $B$ during the interval $[t_0,t)$, where $t_0$ is an arbitrary starting point not later than the first observation.
We use the notation $\cp{\BirthDeath}{S}$ to refer to births and $\cp{A}{\BirthDeath}$ to refer to deaths from compartment A.
Let us assume that the \emph{per capita} birth and death rates, and the rate of transition, $\gamma$, from I to R are constants.
The S to I transition rate, the so-called \emph{force of infection}, $\lambda(t)$, however, should be an increasing function of $I(t)$.
For many infections, it is reasonable to assume that the $\lambda(t)$ is jointly proportional to the fraction of the population infected and the rate at which an individual comes into contact with others.
Here, we will make these assumptions, writing $\lambda(t)=\beta\,I(t)/P$,
where $\beta$ is the transmission rate and $P=S+I+R$ is the population size.
We will go further and assume that birth and death rates are equal and independent of infection status; we will let $\mu$ denote the common rate.
A consequence is that the expected population size remains constant.

The continuous-time Markov process is fully specified by the infinitesimal increment probabilities.
Specifically, writing $\Delta{N(t)}=N(t+h)-N(t)$, we have
\begin{equation}\label{eq:sir-cp}
  \begin{aligned}
    \prob{\Delta{\cp{\BirthDeath}{S}(t)}\myequals 1 \given S(t), I(t), R(t)} &= \mu\,P(t)\,h+o(h), \\
    \prob{\Delta{\cp{S}{I}(t)}\myequals 1 \given S(t), I(t), R(t)} &= \lambda(t)\,S(t)\,h+o(h), \\
    \prob{\Delta{\cp{I}{R}(t)}\myequals 1 \given S(t), I(t), R(t)} &= \gamma\,I(t)\,h+o(h), \\
    \prob{\Delta{\cp{S}{\BirthDeath}(t)}\myequals 1 \given S(t), I(t), R(t) } &= \mu\,S(t)\,h+o(h), \\
    \prob{\Delta{\cp{I}{\BirthDeath}(t)}\myequals 1\given S(t), I(t), R(t)} &= \mu\,I(t)\,h+o(h), \\
    \prob{\Delta{\cp{R}{\BirthDeath}(t)}\myequals 1 \given S(t), I(t), R(t)} &= \mu\,R(t)\,h+o(h),
  \end{aligned}
\end{equation}
together with statement that all events of the form
\begin{equation*}
  \{\Delta{\cp{A}{B}(t)}\,{>}\, 1\} \qquad \text{and} \qquad \{\Delta{\cp{A}{B}(t)}\myequals 1,\Delta{\cp{C}{D}(t)}\myequals 1\}
\end{equation*}
for $A$, $B$, $C$, $D$ with $(A,B)\neq (C,D)$ have probability $o(h)$.
The counting processes are coupled to the state variables \citep{Breto2011} via the following identities
\begin{equation}\label{eq:sir-cp-bal}
  \begin{aligned}
    \Delta{S}(t) &= \Delta{\cp{\BirthDeath}{S}}(t)-\Delta{\cp{S}{I}}(t)-\Delta{\cp{S}{\BirthDeath}}(t),\\
    \Delta{I}(t) &= \Delta{\cp{S}{I}}(t)-\Delta{\cp{I}{R}}(t)-\Delta{\cp{I}{\BirthDeath}}(t),\\
    \Delta{R}(t) &= \Delta{\cp{I}{R}}(t)-\Delta{\cp{R}{\BirthDeath}}(t).\\
  \end{aligned}
\end{equation}
Taking expectations of \cref{eq:sir-cp,eq:sir-cp-bal}, dividing through by $h$, and taking the limit as $h\downarrow~0$, one obtains a system of nonlinear ordinary differential equations which is known as the deterministic skeleton of the model \citep{Coulson2004}.
Specifically, the SIR deterministic skeleton is
\begin{equation}
  \begin{aligned}
    &\frac{dS}{dt}=\mu\,(P-S)-\beta\,\frac{I}{P}\,S,\\
    &\frac{dI}{dt}=\beta\,\frac{I}{P}\,S-\gamma\,I-\mu\,I,\\
    &\frac{dR}{dt}=\gamma\,I-\mu\,R.\\
  \end{aligned}
\end{equation}

It is typically impossible to monitor $S$, $I$, and $R$, directly.
It sometimes happens, however, that public health authorities keep records of \emph{cases}, i.e., individual infections.
The number of cases, $C(t_1,t_2)$, recorded within a given reporting interval $[t_1,t_2)$ might perhaps be modeled by a negative binomial process
\begin{equation}
  C(t_1,t_2)\;\sim\;\mathrm{NegBin}(\rho\,\Delta{\cp{S}{I}}(t_1,t_2),\theta),
\end{equation}
where $\Delta{\cp{S}{I}}(t_1,t_2)$ is the true incidence (the accumulated number of new infections that have occured over the $[t_1,t_2)$ interval), $\rho$ is the \emph{reporting rate}, (the probability that an infection is observed and recorded), $\theta$ is the negative binomial ``size'' parameter, and the notation is meant to indicate that $\E{C(t_1,t_2)\given \Delta{\cp{S}{I}}(t_1,t_2)=H}=\rho\,H$ and $\VAR{C(t_1,t_2)\given \Delta{\cp{S}{I}}(t_1,t_2)=H}=\rho\,H+\rho^2\,H^2/\theta$.
The fact that the observed data are linked to an accumulation, as opposed to an instantaneous value, introduces a slight complication, which we discuss below.

\subsection[Implementing the SIR model in pomp]{Implementing the SIR model in \pkg{pomp}}

As before, we will need to write functions to implement some or all of the SIR model's \code{rprocess}, \code{rmeasure}, and \code{dmeasure} components.
As in \cref{sec:ricker:setup}, we will write these components using \pkg{pomp}'s \code{Csnippet}s.
Recall that these are snippets of \proglang{C} code that \pkg{pomp} automatically assembles, compiles, and dynamically loads into the running \proglang{R} session.

To start with, we will write snippets that specify the measurement model (\code{rmeasure} and \code{dmeasure}):
<<sir-comments,include=FALSE>>=
##' ## More complex models.
##' ### Simple SIR.
##' C snippets expressing the two faces of the measurement model.
<<sir-measmodel>>=
rmeas <- Csnippet("cases = rnbinom_mu(theta, rho * H);")
dmeas <- Csnippet("lik = dnbinom_mu(cases, theta, rho * H, give_log);")
@
Here, we are using \code{cases} to refer to the data (number of reported cases) and \code{H} to refer to the true incidence over the reporting interval.
The negative binomial simulator \code{rnbinom\_mu} and density function \code{dnbinom\_mu} are provided by \proglang{R}.
The logical flag \code{give\_log} requests the likelihood when \code{FALSE}, the log likelihood when \code{TRUE}.
Notice that, in these snippets, we never declare the variables;
\code{pomp} will ensure that the state variable (\code{H}), observable (\code{cases}), parameters (\code{theta}, \code{rho}), and likelihood (\code{lik}) are defined in the contexts within which these snippets are executed.

For the \code{rprocess} portion, we could simulate from the continuous-time Markov process exactly \citep{Gillespie1977};
the \pkg{pomp} function \code{gillespie} implements this algorithm.
However, for practical purposes, the exact algorithm is often prohibitively slow.
If we are willing to live with an approximate simulation scheme, we can use the so-called ``tau-leap'' algorithm, one version of which is implemented in \pkg{pomp} via the \code{euler} plug-in.
This algorithm holds the transition rates $\lambda$, $\mu$, $\gamma$ constant over a small interval of time $\Delta{t}$ and simulates the numbers of births, deaths, and transitions that occur over that interval.
It then updates the state variables $S$, $I$, $R$ accordingly, increments the time variable by $\Delta{t}$, recomputes the transition rates, and repeats.
Naturally, as $\Delta{t}\to 0$, this approximation to the true continuous-time process becomes better and better.
The critical feature from the inference point of view, however, is that no relationship needs to be assumed between the Euler simulation interval $\Delta{t}$ and the reporting interval, which itself does not even need to be the same from one observation to the next.

Under the above assumptions, the number of individuals leaving any of the classes by all available routes over a particular time interval is a multinomial process.
For example, if $\Delta{\cp{S}{I}}$ and $\Delta{\cp{S}{}}$ are the numbers of S individuals acquiring infection and dying, respectively, over the Euler simulation interval $[t,t+\Delta{t})$, then
\begin{equation}\label{eq:eulermultinomial}
    (\Delta{\cp{S}{I}},\Delta{\cp{S}{}},S-\Delta{\cp{S}{I}}-\Delta{\cp{S}{}})\sim\mathrm{Multinom}\left(S(t);p_{S{\to}I},p_{S{\to}},1-p_{S{\to}I}-p_{S{\to}}\right),\\
\end{equation}
where
\begin{equation}\label{eq:eulermultinomial2}
  \begin{aligned}
    p_{S{\to}I} &= \frac{\lambda(t)}{\lambda(t)+\mu}\,\left(1-e^{-(\lambda(t)+\mu)\,\Delta{t}}\right),\\
    p_{S{\to}} &= \frac{\mu}{\lambda(t)+\mu}\,\left(1-e^{-(\lambda(t)+\mu)\,\Delta{t}}\right).
  \end{aligned}
\end{equation}
By way of shorthand, we say that the random variable $(\Delta{\cp{S}{I}},\Delta{\cp{S}{}})$ in \cref{eq:eulermultinomial} has an \emph{Euler-multinomial} distribution.
\pkg{pomp} provides convenience functions for such distributions, which arise with some frequency in compartmental models.
Specifically, the functions \code{reulermultinom} and \code{deulermultinom} respectively draw random deviates from, and evaluate the probability mass function of, such distributions.
As the help pages relate, \code{reulermultinom} and \code{deulermultinom} parameterize the Euler-multinomial distributions by the size ($S(t)$ in \cref{eq:eulermultinomial}), rates ($\lambda(t)$ and $\mu$), and time interval $\Delta{t}$.
Obviously, the Euler-multinomial distributions generalize to an arbitrary number of exit routes.

The help page (\code{?euler}) informs us that to use \code{euler}, we need to specify a function that advances the states from $t$ to $t+\Delta{t}$.
Again, we write this in \proglang{C} to realize faster run-times:
<<sir-step-comments,include=FALSE>>=
##' The process model simulator.
##' This takes one step from time t -> t+dt
##' The per-capita rates of the elementary transitions are stored in 'rate'.
##' The numbers of individuals making each transition is stored in 'trans'.
##' Births are Poisson, transitions are Euler-multinomial.
##' 'H' accumulates the recoveries (and will be zeroed after each observation).
<<sir-proc-sim-def>>=
sir.step <- Csnippet("
  double rate[6];
  double dN[6];
  double P;
  P = S + I + R;
  rate[0] = mu * P;       // birth
  rate[1] = Beta * I / P; // transmission
  rate[2] = mu;           // death from S
  rate[3] = gamma;        // recovery
  rate[4] = mu;           // death from I
  rate[5] = mu;           // death from R
  dN[0] = rpois(rate[0] * dt);
  reulermultinom(2, S, &rate[1], dt, &dN[1]);
  reulermultinom(2, I, &rate[3], dt, &dN[3]);
  reulermultinom(1, R, &rate[5], dt, &dN[5]);
  S += dN[0] - dN[1] - dN[2];
  I += dN[1] - dN[3] - dN[4];
  R += dN[3] - dN[5];
  H += dN[1];")

rinit <- Csnippet("
  S = nearbyint(popsize*S_0 / (S_0+I_0+R_0));
  I = nearbyint(popsize*I_0 / (S_0+I_0+R_0));
  R = nearbyint(popsize*R_0 / (S_0+I_0+R_0));
  H = 0;")
@

As before, \pkg{pomp} will ensure that the undeclared state variables and parameters are defined in the context within which the snippet is executed.
Note, however, that in the above we do declare certain local variables.
In particular, the \code{rate} and \code{dN} arrays hold the rates and numbers of transition events, respectively.
Note too, that we make use of \pkg{pomp}'s \proglang{C} interface to \code{reulermultinom}, documented in the package help pages (\code{?reulermultinom}).
The package help system (\code{?Csnippet}) includes instructions for, and examples of, the use of \code{Csnippet}s.

Two significant wrinkles remain to be explained.
First, notice that in \code{sir.step}, the variable \code{H} simply accumulates the numbers of new infections: \code{H} is a counting process that is nondecreasing with time.
In fact, the incidence within an interval $[t_1,t_2)$ is $\Delta{\cp{S}{I}}(t_1,t_2)=\mathtt{H}(t_2)-\mathtt{H}(t_1)$.
This leads to a technical difficulty with the measurement process, however, in that the data are assumed to be records of new infections occurring within the latest reporting interval, while the process model tracks the accumulated number of new infections since time $t_0$.
We can get around this difficulty by re-setting \code{H} to zero immediately after each observation.
We cause \pkg{pomp} to do this via the \code{pomp} function's \code{zeronames} argument, as we will see in a moment.
The section on ``accumulator variables'' in the \code{pomp} help page (\code{?pomp}) discusses this in more detail.

The second wrinkle has to do with the initial conditions, i.e., the states $S(t_0)$, $I(t_0)$, $R(t_0)$.
By default, \pkg{pomp} will allow us to specify these initial states arbitrarily.
For the model to be consistent, they should be positive integers that sum to the population size $N$.
We can enforce this constraint by customizing the parameterization of our initial conditions.
We do this by furnishing a custom \code{rinit} in the call to \code{pomp}.
Let us construct it now and fill it with simulated data.
<<sir-pomp-comment,include=FALSE>>=
##' Construct the pomp object and fill with simulated data.
@
<<sir-pomp-def,results="hide",tidy=FALSE>>=
sir1 <- simulate(times =seq(0,10,by=1/52), t0 = -1/52,
  dmeasure = dmeas, rmeasure = rmeas, rinit = rinit,
  rprocess = euler(step.fun = sir.step, delta.t = 1/52/20),
  statenames = c("S", "I", "R", "H"), accumvars="H", obsnames="cases",
  paramnames = c("gamma", "mu", "theta", "Beta", "popsize", "rho",
    "S_0", "I_0", "R_0"), params = c(popsize = 500000, Beta = 400,
      gamma = 26, mu = 1/50, rho = 0.1, theta = 100, S_0 = 26/400,
      I_0 = 0.002, R_0 = 1), seed = 1914679908L)
@

Notice that we are assuming here that the data are collected weekly and use an Euler step-size of 1/20~wk.
Here, we have assumed an infectious period of 2~wk ($1/\gamma=1/26$~yr) and a basic reproductive number, $R_0$ of $\beta/(\gamma+\mu)\approx 15$.
We have assumed a host population size of 500,000 and 10\% reporting efficiency.
\cref{fig:sir1-plot} shows one realization of this process.

\begin{figure}[t!]
<<sir1-plot,echo=FALSE,fig.height=5>>=
ops <- options(scipen=-10)
plot(sir1,mar=c(0,5,2,0))
options(ops)
@
  \caption{
    Result of \code{plot(sir1)}.
    The class-\class{pomp} object \code{sir1} contains the SIR model with simulated data.
  }
  \label{fig:sir1-plot}
\end{figure}

\subsection{Incorporating additional model complexity}

To illustrate the flexibility afforded by \pkg{pomp}'s plug-and-play methods, let us add a bit of real-world complexity to the simple SIR model.
We will modify the model to take four facts into account:
\begin{enumerate}
  \item For many infections, the contact rate is \emph{seasonal}: $\beta=\beta(t)$ varies in more or less periodic fashion with time.
  \item The host population may not be truly closed: \emph{imported infections} arise when infected individuals visit the host population and transmit.
  \item The host population does not need to be constant in size.
    If we have data, for example, on the numbers of births occurring in the population, we can incorporate this directly into the model.
  \item Stochastic fluctuation in the rates $\lambda$, $\mu$, and $\gamma$ can give rise to \emph{extrademographic stochasticity}, i.e., random process variability beyond the purely demographic stochasticity we have included so far.
\end{enumerate}

To incorporate seasonality, we would like to assume a flexible functional form for $\beta(t)$.
Here, we will use a three-coefficient Fourier series:
\begin{equation}
  \log{\beta(t)}=b_0+b_1\,\cos{2\pi t}+b_2\sin{2\pi t}.
\end{equation}

There are a variety of ways to account for imported infections.
Here, we will simply assume that there is some constant number, $\iota$, of infected hosts visiting the population.
Putting this together with the seasonal contact rate results in a force of infection $\lambda(t)=\beta(t)\,\left(I(t)+\iota\right)/N$.

To incorporate birth-rate information, let us suppose we have data on the number of births occurring each month in this population and that these data are in the form of a data frame \code{birthdat} with columns \code{time} and \code{births}.
We can incorporate the varying birth rate into our model by passing it as a covariate to the simulation code.
When we pass \code{birthdat} as the \code{covar} argument to \code{pomp}, we cause a look-up table to be created and made available to the simulator.
The package employs linear interpolation to provide a value of each variable in the covariate table at any requisite time:
from the user's perspective, a variable \code{births} will simply be available for use by the model codes.

<<birthdat,eval=TRUE,echo=FALSE,results="hide">>=
##' Construct some fake birthrate data.
birthdat <- data.frame(time=seq(-1,11,by=1/12))
birthdat$births <- 5e5*bspline_basis(birthdat$time,nbasis=5)%*%c(0.018,0.019,0.021,0.019,0.015)
freeze(seed=5853712L,{
  birthdat$births <- ceiling(rlnorm(
    n=nrow(birthdat),
    meanlog=log(birthdat$births),
    sdlog=0.001
  ))
})
@

Finally, we can allow for extrademographic stochasticity by allowing the force of infection to be itself a random variable.
We will accomplish this by assuming a random phase in $\beta$:
\begin{equation}
  \lambda(t) = \left(\beta(\Phi(t))\,\frac{I(t)+\iota}{N}\right),
\end{equation}
where the phase $\Phi$ satisfies the stochastic differential equation
\begin{equation}
  d\Phi=dt+\sigma\,dW_t,
\end{equation}
where $dW(t)$ is a white noise, specifically an increment of standard Brownian motion.
This model assumption attempts to capture variability in the timing of seasonal changes in transmission rates.
As $\sigma$ varies, it can represent anything from a very mild modulation of the timing of the seasonal progression to much more intense variation.

Let us modify the process-model simulator to incorporate these complexities.
<<complex-sir-comment,include=FALSE>>=
##' ### Complex SIR model.
##' This has seasonal forcing, covariates, extrademographic stochasticity,
##' and imported infections.

##' The main difference from 'sir1' is in the process model simulator.
##' 'beta' is the transmission rate, which varies according to the random variable 'phase'.
##' 'iota' is the effective number of imported infections (assumed constant).
##' 'births' is interpolated from the covariate table 'birthdat'
<<complex-sir-def,echo=TRUE,eval=TRUE,results="hide",tidy=FALSE>>=
seas.sir.step <- Csnippet("
  double rate[6];
  double dN[6];
  double Beta;
  double dW;
  Beta = exp(b1 + b2 * cos(M_2PI * Phi) + b3 * sin(M_2PI * Phi));
  rate[0] = births;                // birth
  rate[1] = Beta * (I + iota) / P; // infection
  rate[2] = mu;                    // death from S
  rate[3] = gamma;                 // recovery
  rate[4] = mu;                    // death from I
  rate[5] = mu;                    // death from R
  dN[0] = rpois(rate[0] * dt);
  reulermultinom(2, S, &rate[1], dt, &dN[1]);
  reulermultinom(2, I, &rate[3], dt, &dN[3]);
  reulermultinom(1, R, &rate[5], dt, &dN[5]);
  dW = rnorm(dt, sigma * sqrt(dt));
  S += dN[0] - dN[1] - dN[2];
  I += dN[1] - dN[3] - dN[4];
  R += dN[3] - dN[5];
  P = S + I + R;
  Phi += dW;
  H += dN[1];
  noise += (dW - dt) / sigma;")

seas.rinit <- Csnippet("
  S = nearbyint(popsize*S_0 / (S_0+I_0+R_0));
  I = nearbyint(popsize*I_0 / (S_0+I_0+R_0));
  R = nearbyint(popsize*R_0 / (S_0+I_0+R_0));
  P = popsize;
  H = Phi = noise = 0;")

sir2 <- simulate(sir1, dmeasure = dmeas, rmeasure = rmeas,
  rprocess = euler(seas.sir.step, delta.t = 1/52/20),
  covar = covariate_table(birthdat, order="linear", times = "time"),
  rinit = seas.rinit, accumvars = c("H", "noise"),
  statenames = c("S", "I", "R", "H", "P", "Phi", "noise"),
  paramnames = c("gamma", "mu", "popsize", "rho", "theta", "sigma",
                 "S_0", "I_0", "R_0", "b1", "b2", "b3", "iota"),
  params = c(popsize = 500000, iota = 5, b1 = 6, b2 = 0.2, b3 = -0.1,
    gamma = 26, mu = 1/50, rho = 0.1, theta = 100, sigma = 0.3,
    S_0 = 0.055, I_0 = 0.002, R_0 = 0.94), seed = 619552910L)
@
\Cref{fig:sir2-plot} shows the simulated data and latent states.
The \code{sir2} object we have constructed here contains all the key elements of models used within \pkg{pomp} to investigate cholera \citep{King2008}, measles \citep{He2010}, malaria \citep{Bhadra2011}, pertussis \citep{Blackwood2013,Lavine2013}, pneumococcal pneumonia \citep{Shrestha2013}, rabies \citep{Blackwood2013b}, and Ebola virus disease \citep{King2015}.

\begin{figure}[t!]
<<sir2-plot,echo=FALSE,fig.height=6.5>>=
ops <- options(scipen=-10)
plot(sir2,mar=c(0,5,2,0))
options(ops)
@
  \caption{
    One realization of the SIR model with seasonal contact rate, imported infections, and extrademographic stochasticity in the force of infection.
    %%    The $W$ state-variable is an unbiased random walk that is the accumulation of the white-noise increments \code{dW}.
}
  \label{fig:sir2-plot}
\end{figure}

\section{Conclusion}
\label{sec:conclusion}

The \pkg{pomp} package is designed to be both a tool for data analysis based on POMP models and a sound platform for the development of inference algorithms.
The model specification language provided by \pkg{pomp} is very general.
Implementing a POMP model in \pkg{pomp} makes a wide range of inference algorithms available.
Moreover, the separation of model specification from the inference algorithm facilitates objective comparison of alternative models and methods.
The examples demonstrated in this paper are relatively simple, but the package has been instrumental in a number of scientific studies \citep[e.g.,][]{King2008,Bhadra2011,Shrestha2011,Earn2012,Roy2013,Shrestha2013,Blackwood2013,Blackwood2013b,Lavine2013,He2013a,Breto2014,King2015}.

As a development platform, \pkg{pomp} is particularly convenient for implementing algorithms with the plug-and-play property, since models will typically be defined by their \code{rprocess} simulator, together with \code{rmeasure} and often \code{dmeasure}, but can accommodate inference methods based on other model components such as \code{dprocess} and \code{skeleton} (the deterministic skeleton of the latent process).
As an open-source project, the package readily supports expansion, and the authors invite community participation in the \pkg{pomp} project in the form of additional inference algorithms, improvements and extensions of existing algorithms, additional model/data examples, documentation contributions and improvements, bug reports, and feature requests.

Complex models and large datasets can challenge computational resources.
With this in mind, key components of the \pkg{pomp} package are written in \proglang{C}, and \pkg{pomp} provides facilities for users to write models either in \proglang{R} or, for the acceleration that typically proves necessary in applications, in \proglang{C}.
Multi-processor computing also becomes necessary for ambitious projects.
The two most common computationally intensive tasks are the assessment of Monte~Carlo variability and the investigation of the roles of starting values and other algorithmic settings on optimization routines.
These analyses require only embarrassingly parallel computations and need no special discussion here.

The package contains more examples, which can be used as templates for implementation of new models;
the \proglang{R} and \proglang{C} codes underlying these examples are provided with the package.
Further documentation and an introductory tutorial are provided with the package and on the \pkg{pomp} website, \url{https://kingaa.github.io/pomp}.

\section*{Acknowledgments}

Initial development of \pkg{pomp} was carried out as part of the {\it Inference for Mechanistic Models} working group supported from 2007 to 2010 by the National Center for Ecological Analysis and Synthesis, a center funded by the U.S.\ National Science Foundation (Grant DEB-0553768), the University of California, Santa Barbara, and the State of California.
Participants were C.~Bret\'{o}, S.~P.~Ellner, M.~J.~Ferrari, G.~J.~Gibson, G.~Hooker, E.~L.~Ionides, V.~Isham, B.~E.~Kendall, K.~Koelle, A.~A.~King, M.~L.~Lavine, K.~B.~Newman, D.~C.~Reuman, P.~Rohani and H.~J.~Wearing.
M.~Wang prepared a first draft of this revision.
Financial support was provided by grants \#DMS-1308919, \#DMS-0805533, and \#EF-0429588 from the U.S.\ National Science Foundation, by grants \#1U54GM111274 and \#1R01AI101155 from the U.S. National Institutes of Health, by grant \#1761603 from the Joint NSF/NIH Interface program, and by the Research and Policy for Infectious Disease Dynamics program of the Science and Technology Directorate, U.S.\ Department of Homeland Security and the Fogarty International Center, U.S.\ National Institutes of Health.

\begin{thebibliography}{65}
\newcommand{\enquote}[1]{``#1''}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\providecommand{\urlprefix}{URL }
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi:\discretionary{}{}{}#1}\else
  \providecommand{\doi}{doi:\discretionary{}{}{}\begingroup
  \urlstyle{rm}\Url}\fi
\providecommand{\eprint}[2][]{\url{#2}}

\bibitem[{Anderson and May(1991)}]{Anderson1991}
Anderson R, May R (1991).
\newblock \emph{Infectious Diseases of Humans}.
\newblock Oxford University Press, Oxford.

\bibitem[{Andrieu \emph{et~al.}(2010)Andrieu, Doucet, and Holenstein}]{Andrieu2010}
Andrieu C, Doucet A, Holenstein R (2010).
\newblock \enquote{Particle {M}arkov Chain {M}onte {C}arlo Methods.}
\newblock \emph{Journal of the Royal Statistical Society B}, \textbf{72}(3),
  269--342.
\newblock \doi{10.1111/j.1467-9868.2009.00736.x}.

\bibitem[{Andrieu and Roberts(2009)}]{Andrieu2009}
Andrieu C, Roberts G (2009).
\newblock \enquote{The Pseudo-Marginal Approach for Efficient Computation.}
\newblock \emph{The Annals of Statistics}, \textbf{37}(2), 697--725.
\newblock \doi{10.1214/07-aos574}.

\bibitem[{Arulampalam \emph{et~al.}(2002)Arulampalam, Maskell, Gordon, and Clapp}]{Arulampalam2002}
Arulampalam M, Maskell S, Gordon N, Clapp T (2002).
\newblock \enquote{A Tutorial on Particle Filters for Online Nonlinear, Non-{G}aussian {B}ayesian Tracking.}
\newblock \emph{IEEE Transactions on Signal Processing}, \textbf{50}, 174--188.
\newblock \doi{10.1109/78.978374}.

\bibitem[{Beaumont(2010)}]{Beaumont2010}
Beaumont M (2010).
\newblock \enquote{Approximate {B}ayesian Computation in Evolution and Ecology.}
\newblock \emph{Annual Review of Ecology, Evolution, and Systematics},
  \textbf{41}, 379--406.
\newblock \doi{10.1146/annurev-ecolsys-102209-144621}.

\bibitem[{Bhadra(2010)}]{Bhadra2010}
Bhadra A (2010).
\newblock \enquote{Discussion of `{P}article {M}arkov Chain {M}onte {C}arlo Methods' by {C}.~{A}ndrieu, {A}.~{D}oucet and {R}.~{H}olenstein.}
\newblock \emph{Journal of the Royal Statistical Society B}, \textbf{72},
  314--315.
\newblock \doi{10.1111/j.1467-9868.2009.00736.x}.

\bibitem[{Bhadra \emph{et~al.}(2011)Bhadra, Ionides, Laneri, Pascual, Bouma, and Dhiman}]{Bhadra2011}
Bhadra A, Ionides E, Laneri K, Pascual M, Bouma M, Dhiman R (2011).
\newblock \enquote{Malaria in {N}orthwest {I}ndia: Data Analysis via Partially Observed Stochastic Differential Equation Models Driven by {L}{\'e}vy Noise.}
\newblock \emph{Journal of the American Statistical Association},
  \textbf{106}(494), 440--451.
\newblock \doi{10.1198/jasa.2011.ap10323}.

\bibitem[{Blackwood \emph{et~al.}(2013{\natexlab{a}})Blackwood, Cummings, Broutin, Iamsirithaworn, and Rohani}]{Blackwood2013}
Blackwood J, Cummings D, Broutin H, Iamsirithaworn S, Rohani P
  (2013{\natexlab{a}}).
\newblock \enquote{Deciphering the Impacts of Vaccination and Immunity on Pertussis Epidemiology in {T}hailand.}
\newblock \emph{Proceedings of the National Academy of Sciences of the United States of America}, \textbf{110}(23), 9595--9600.
\newblock \doi{10.1073/pnas.1220908110}.

\bibitem[{Blackwood \emph{et~al.}(2013{\natexlab{b}})Blackwood, Streicker, Altizer, and Rohani}]{Blackwood2013b}
Blackwood J, Streicker D, Altizer S, Rohani P (2013{\natexlab{b}}).
\newblock \enquote{Resolving the Roles of Immunity, Pathogenesis, and Immigration for Rabies Persistence in Vampire Bats.}
\newblock \emph{Proceedings of the National Academy of Sciences of the United States of America}, \textbf{110}(51), 20837--20842.
\newblock \doi{10.1073/pnas.1308817110}.

\bibitem[{Blake \emph{et~al.}(2014)Blake, Martin, Goel, Khetsuriani, Everts, Wolff, Wassilak, Aylward, and Grassly}]{Blake2014}
Blake I, Martin R, Goel A, Khetsuriani N, Everts J, Wolff C, Wassilak S, Aylward R, Grassly N (2014).
\newblock \enquote{The Role of Older Children and Adults in Wild Poliovirus Transmission.}
\newblock \emph{Proceedings of the National Academy of Sciences of the United States of America}, \textbf{111}(29), 10604--10609.
\newblock \doi{10.1073/pnas.1323688111}.

\bibitem[{Bret{\'o}(2014)}]{Breto2014}
Bret{\'o} C (2014).
\newblock \enquote{On Idiosyncratic Stochasticity of Financial Leverage Effects.}
\newblock \emph{Statistics \& Probability Letters}, \textbf{91}, 20--26.
\newblock \doi{10.1016/j.spl.2014.04.003}.

\bibitem[{Bret{\'o} \emph{et~al.}(2009)Bret{\'o}, He, Ionides, and King}]{Breto2009}
Bret{\'o} C, He D, Ionides E, King AA (2009).
\newblock \enquote{Time Series Analysis via Mechanistic Models.}
\newblock \emph{The Annals of Applied Statistics}, \textbf{3}, 319--348.
\newblock \doi{10.1214/08-aoas201}.

\bibitem[{Bret{\'o} and Ionides(2011)}]{Breto2011}
Bret{\'o} C, Ionides E (2011).
\newblock \enquote{Compound {M}arkov Counting Processes and Their Applications to Modeling Infinitesimally Over-Dispersed Systems.}
\newblock \emph{Stochastic Processes and their Applications}, \textbf{121}(11), 2571--2591.
\newblock \doi{10.1016/j.spa.2011.07.005}.

\bibitem[{Capp{\'e} \emph{et~al.}(2007)Capp{\'e}, Godsill, and Moulines}]{Cappe2007}
Capp{\'e} O, Godsill SJ, Moulines E (2007).
\newblock \enquote{An Overview of Existing Methods and Recent Advances in Sequential {M}onte {C}arlo.}
\newblock \emph{Proceedings of the IEEE}, \textbf{95}(5), 899--924.
\newblock \doi{10.1109/jproc.2007.893250}.

\bibitem[{Chambers(1998)}]{Chambers1998}
Chambers J (1998).
\newblock \emph{Programming with Data}.
\newblock Springer-Verlag, New York.

\bibitem[{Commandeur \emph{et~al.}(2011)Commandeur, Koopman, and Ooms}]{Commandeur2011}
Commandeur J, Koopman S, Ooms M (2011).
\newblock \enquote{Statistical Software for State Space Methods.}
\newblock \emph{Journal of Statistical Software}, \textbf{41}(1), 1--18.
\newblock \doi{10.18637/jss.v041.i01}.

\bibitem[{Coulson \emph{et~al.}(2004)Coulson, Rohani, and Pascual}]{Coulson2004}
Coulson T, Rohani P, Pascual M (2004).
\newblock \enquote{Skeletons, Noise and Population Growth: The End of an Old Debate?}
\newblock \emph{Trends in Ecology and Evolution}, \textbf{19}, 359--364.
\newblock \doi{10.1016/j.tree.2004.05.008}.

\bibitem[{Douc \emph{et~al.}(2005)Douc, Capp{\'e}, and Moulines}]{Douc2005}
Douc R, Capp{\'e} O, Moulines E (2005).
\newblock \enquote{Comparison of Resampling Schemes for Particle Filtering.}
\newblock In \emph{Proceedings of the 4th International Symposium on Image and Signal Processing and Analysis, 2005}, pp. 64--69. IEEE.
\newblock \doi{10.1109/ispa.2005.195385}.

\bibitem[{Doucet and Johansen(2009)}]{Doucet2009}
Doucet A, Johansen A (2009).
\newblock \enquote{A Tutorial on Particle Filtering and Smoothing: Fifteen Years Later.}
\newblock In D~Crisan, B~Rozovsky (eds.), \emph{Oxford Handbook of Nonlinear Filtering}. Oxford University Press.

\bibitem[{Earn \emph{et~al.}(2012)Earn, He, Loeb, Fonseca, Lee, and Dushoff}]{Earn2012}
Earn D, He D, Loeb M, Fonseca K, Lee B, Dushoff J (2012).
\newblock \enquote{Effects of School Closure on Incidence of Pandemic Influenza in Alberta, Canada.}
\newblock \emph{The Annals of Internal Medicine}, \textbf{156}(3), 173--181.
\newblock \doi{10.7326/0003-4819-156-3-201202070-00005}.

\bibitem[{Ellner \emph{et~al.}(1998)Ellner, Bailey, Bobashev, Gallant, Grenfell, and Nychka}]{Ellner1998}
Ellner S, Bailey B, Bobashev G, Gallant A, Grenfell B, Nychka D (1998).
\newblock \enquote{Noise and Nonlinearity in Measles Epidemics: Combining Mechanistic and Statistical Approaches to Population Modeling.}
\newblock \emph{American Naturalist}, \textbf{151}(5), 425--440.
\newblock \doi{10.1086/286130}.

\bibitem[{Genolini(2008)}]{Genolini2008}
Genolini C (2008).
\newblock \enquote{A (Not So) Short Introduction to \proglang{S}4.}
\newblock \proglang{R} Foundation for Statistical Computing.
\newblock \urlprefix\url{https://CRAN.R-project.org/doc/contrib/Genolini-S4tutorialV0-5en.pdf}.

\bibitem[{Gillespie(1977)}]{Gillespie1977}
Gillespie D (1977).
\newblock \enquote{Exact Stochastic Simulation of Coupled Chemical Reactions.}
\newblock \emph{Journal of Physical Chemistry}, \textbf{81}(25), 2340--2361.
\newblock \doi{10.1021/j100540a008}.

\bibitem[{Gompertz(1825)}]{Gompertz1825}
Gompertz B (1825).
\newblock \enquote{On the Nature of the Function Expressive of the Law of Human Mortality, and on a New Mode of Determining the Value of Life Contingencies.}
\newblock \emph{Philosophical Transactions of the Royal Society of London}, \textbf{115}, 513--583.
\newblock \doi{10.1098/rstl.1825.0026}.

\bibitem[{He \emph{et~al.}(2013)He, Dushoff, Day, Ma, and Earn}]{He2013a}
He D, Dushoff J, Day T, Ma J, Earn D (2013).
\newblock \enquote{Inferring the Causes of the Three Waves of the 1918 Influenza Pandemic in England and Wales.}
\newblock \emph{Proceedings of the Royal Society of London B}, \textbf{280}(1766), 20131345.
\newblock \doi{10.1098/rspb.2013.1345}.

\bibitem[{He \emph{et~al.}(2010)He, Ionides, and King}]{He2010}
He D, Ionides E, King AA (2010).
\newblock \enquote{Plug-and-Play Inference for Disease Dynamics: Measles in Large and Small Towns as a Case Study.}
\newblock \emph{Journal of the Royal Society Interface}, \textbf{7}(43), 271--283.
\newblock \doi{10.1098/rsif.2009.0151}.

\bibitem[{Ionides(2011)}]{Ionides2011b}
Ionides E (2011).
\newblock \enquote{Discussion of ``{F}eature Matching in Time Series Modeling'' by {Y}.~{X}ia and {H}.~{T}ong.}
\newblock \emph{Statistical Science}, \textbf{26}, 49--52.
\newblock \doi{10.1214/11-sts345c}.

\bibitem[{Ionides \emph{et~al.}(2011)Ionides, Bhadra, Atchad{\'e}, and King}]{Ionides2011}
Ionides E, Bhadra A, Atchad{\'e} Y, King AA (2011).
\newblock \enquote{Iterated Filtering.}
\newblock \emph{The Annals of Statistics}, \textbf{39}(3), 1776--1802.
\newblock \doi{10.1214/11-aos886}.

\bibitem[{Ionides \emph{et~al.}(2006)Ionides, Bret{\'o}, and King}]{Ionides2006}
Ionides E, Bret{\'o} C, King AA (2006).
\newblock \enquote{Inference for Nonlinear Dynamical Systems.}
\newblock \emph{Proceedings of the National Academy of Sciences of the United States of America}, \textbf{103}(49), 18438--18443.
\newblock \doi{10.1073/pnas.0603181103}.

\bibitem[{Ionides \emph{et~al.}(2015)Ionides, Nguyen, Atchad{\'e}, Stoev, and King}]{Ionides2015}
Ionides E, Nguyen D, Atchad{\'e} Y, Stoev S, King AA (2015).
\newblock \enquote{Inference for Dynamic and Latent Variable Models via Iterated, Perturbed {B}ayes Maps.}
\newblock \emph{Proceedings of the National Academy of Sciences of the United States of America}, \textbf{112}(3), 719--724.
\newblock \doi{10.1073/pnas.1410597112}.

\bibitem[{Johnson(2014)}]{Johnson2014}
Johnson S (2014).
\newblock \emph{The \pkg{NLopt} Nonlinear-Optimization Package}.
\newblock Version 2.4.2, \urlprefix\url{http://ab-initio.mit.edu/nlopt}.

\bibitem[{Kane \emph{et~al.}(2013)Kane, Emerson, and Weston}]{Kane2013}
Kane M, Emerson J, Weston S (2013).
\newblock \enquote{Scalable Strategies for Computing with Massive Data.}
\newblock \emph{Journal of Statistical Software}, \textbf{55}(1).
\newblock \doi{10.18637/jss.v055.i14}.

\bibitem[{Kantas \emph{et~al.}(2015)Kantas, Doucet, Singh, and Maciejowski}]{Kantas2015}
Kantas N, Doucet A, Singh S, Maciejowski J (2015).
\newblock \enquote{On Particle Methods for Parameter Estimation in State-Space Models.}
\newblock \emph{Statistical Science}, \textbf{30}(3), 328--351.
\newblock \doi{doi:10.1214/14-STS511}.

\bibitem[{Keeling and Rohani(2008)}]{Keeling2008a}
Keeling M, Rohani P (2008).
\newblock \emph{Modeling Infectious Diseases in Humans and Animals}.
\newblock Princeton University Press, Princeton.

\bibitem[{Kendall \emph{et~al.}(1999)Kendall, Briggs, Murdoch, Turchin, Ellner, McCauley, Nisbet, and Wood}]{Kendall1999}
Kendall B, Briggs C, Murdoch W, Turchin P, Ellner S, McCauley E, Nisbet R, Wood S (1999).
\newblock \enquote{Why Do Populations Cycle? {A} Synthesis of Statistical and Mechanistic Modeling Approaches.}
\newblock \emph{Ecology}, \textbf{80}(6), 1789--1805.
\newblock \doi{10.1890/0012-9658(1999)080[1789:wdpcas]2.0.co;2}.

\bibitem[{Kendall \emph{et~al.}(2005)Kendall, Ellner, McCauley, Wood, Briggs, Murdoch, and Turchin}]{Kendall2005}
Kendall B, Ellner S, McCauley E, Wood S, Briggs C, Murdoch W, Turchin P (2005).
\newblock \enquote{Population Cycles in the Pine Looper Moth: {D}ynamical Tests of Mechanistic Hypotheses.}
\newblock \emph{Ecological Monographs}, \textbf{75}(2), 259--276.
\newblock \doi{10.1890/03-4056}.

\bibitem[{Kermack and McKendrick(1927)}]{Kermack1927}
Kermack W, McKendrick A (1927).
\newblock \enquote{A Contribution to the Mathematical Theory of Epidemics.}
\newblock \emph{Proceedings of the Royal Society of London A}, \textbf{115}, 700--721.
\newblock \doi{10.1098/rspa.1927.0118}.

\bibitem[{King \emph{et~al.}(2015)King, Domenech de Cell{\`e}s, Magpantay, and Rohani}]{King2015}
King AA, Domenech de Cell{\`e}s M, Magpantay F, Rohani P (2015).
\newblock \enquote{Avoidable Errors in the Modelling of Outbreaks of Emerging Pathogens, with Special Reference to Ebola.}
\newblock \emph{Proceedings of the Royal Society of London B}, \textbf{282}(1806), 20150347.
\newblock \doi{10.1098/rspb.2015.0347}.

\bibitem[{King \emph{et~al.}(2008)King, Ionides, Pascual, and Bouma}]{King2008}
King AA, Ionides E, Pascual M, Bouma M (2008).
\newblock \enquote{Inapparent Infections and Cholera Dynamics.}
\newblock \emph{Nature}, \textbf{454}(7206), 877--880.
\newblock \doi{10.1038/nature07084}.

\bibitem[{King(2022)}]{subplex}
King AA and Rowan T (2022).
\newblock \emph{\pkg{subplex}: Unconstrained Optimization Using the Subplex Algorithm}.
\newblock \proglang{R}~package, version~1.8,
  \urlprefix\url{https://CRAN.R-project.org/package=subplex}.

\bibitem[{King \emph{et~al.}(2022)King, Ionides, Bret\'o, Ellner, Ferrari, Funk, Johnson, Kendall, Lavine, Nguyen, O'Dea, Reuman, Wearing, and Wood}]{pomp}
King AA, Ionides EL, Bret\'o CM, Ellner SP, Ferrari MJ, Funk S, Johnson SG, Kendall BE, Lavine M, Nguyen D, O'Dea EB, Reuman DC, Wearing H, Wood SN (2022).
\newblock \emph{{pomp}: {Statistical} Inference for Partially Observed {Markov} Processes}.
\newblock \proglang{R}~package, version~4.2, \urlprefix\url{https://kingaa.github.io/pomp/}.

\bibitem[{Kitagawa(1998)}]{Kitagawa1998}
Kitagawa G (1998).
\newblock \enquote{A Self-Organising State Space Model.}
\newblock \emph{Journal of the American Statistical Association}, \textbf{93}(443), 1203--1215.
\newblock \doi{10.1080/01621459.1998.10473780}.

\bibitem[{Lavine \emph{et~al.}(2013)Lavine, King, Andreasen, and Bj{\o}rnstad}]{Lavine2013}
Lavine J, King AA, Andreasen V, Bj{\o}rnstad O (2013).
\newblock \enquote{Immune Boosting Explains Regime-Shifts in Prevaccine-Era Pertussis Dynamics.}
\newblock \emph{PLoS ONE}, \textbf{8}(8), e72086.
\newblock \doi{10.1371/journal.pone.0072086}.

\bibitem[{Liu(2001)}]{Liu2001a}
Liu J (2001).
\newblock \emph{Monte {C}arlo Strategies in Scientific Computing}.
\newblock Springer-Verlag, New York.
\newblock \doi{10.1007/978-0-387-76371-2}.

\bibitem[{Liu and West(2001)}]{Liu2001}
Liu J, West M (2001).
\newblock \enquote{Combining Parameter and State Estimation in Simulation-Based Filtering.}
\newblock In A~Doucet, N~Freitas, N~Gordon (eds.), \emph{Sequential {M}onte {C}arlo Methods in Practice}, pp. 197--224. Springer-Verlag, New York.

\bibitem[{Marin \emph{et~al.}(2012)Marin, Pudlo, Robert, and Ryder}]{Marin2012}
Marin JM, Pudlo P, Robert CP, Ryder R (2012).
\newblock \enquote{Approximate Bayesian Computational Methods.}
\newblock \emph{Statistics and Computing}, \textbf{22}(6), 1167--1180.
\newblock \doi{10.1007/s11222-011-9288-2}.

\bibitem[{Ratmann \emph{et~al.}(2009)Ratmann, Andrieu, Wiuf, and Richardson}]{Ratmann2009}
Ratmann O, Andrieu C, Wiuf C, Richardson S (2009).
\newblock \enquote{Model Criticism Based on Likelihood-Free Inference, with an Application to Protein Network Evolution.}
\newblock \emph{Proceedings of the National Academy of Sciences of the United States of America}, \textbf{106}(26), 10576--10581.
\newblock \doi{10.1073/pnas.0807882106}.

\bibitem[{{\proglang{R} Core Team}(2022)}]{R}
{\proglang{R} Core Team} (2022).
\newblock \emph{\proglang{R}: {A} Language and Environment for Statistical Computing}.
\newblock \proglang{R} Foundation for Statistical Computing, Vienna, Austria.
\newblock \urlprefix\url{https://www.R-project.org/}.

\bibitem[{Reddingius(1971)}]{Reddingius1971}
Reddingius J (1971).
\newblock \emph{Gambling for Existence. A Discussion of Some Theoretical Problems in Animal Population Ecology}.
\newblock B. J. Brill, Leiden.

\bibitem[{Reuman \emph{et~al.}(2006)Reuman, Desharnais, Costantino, Ahmad, and Cohen}]{Reuman2006}
Reuman D, Desharnais R, Costantino R, Ahmad O, Cohen J (2006).
\newblock \enquote{Power Spectra Reveal the Influence Of Stochasticity on Nonlinear Population Dynamics.}
\newblock \emph{Proceedings of the National Academy of Sciences of the United States of America}, \textbf{103}(49), 18860--18865.
\newblock \doi{10.1073/pnas.0608571103}.

\bibitem[{{Revolution Analytics} and Weston(2014)}]{foreach}
{Revolution Analytics}, Weston S (2014).
\newblock \emph{\pkg{foreach}: Foreach Looping Construct for \proglang{R}}.
\newblock \proglang{R} package version 1.4.2, \urlprefix\url{https://CRAN.R-project.org/package=foreach}.

\bibitem[{Ricker(1954)}]{Ricker1954}
Ricker W (1954).
\newblock \enquote{Stock and Recruitment.}
\newblock \emph{Journal of the Fisheries Research Board of Canada}, \textbf{11}, 559--623.
\newblock \doi{10.1139/f54-039}.

\bibitem[{Rowan(1990)}]{Rowan1990}
Rowan T (1990).
\newblock \emph{Functional Stability Analysis of Numerical Algorithms}.
\newblock Ph.D. thesis, Department of Computer Sciences, University of Texas at Austin.

\bibitem[{Roy \emph{et~al.}(2012)Roy, Bouma, Ionides, {Dhiman}, C., and Pascual}]{Roy2013}
Roy M, Bouma M, Ionides E, {Dhiman}, C R, Pascual M (2012).
\newblock \enquote{The Potential Elimination of {{\it {P}lasmodium Vivax}} Malaria by Relapse Treatment: {I}nsights from a Transmission Model and Surveillance Data from {NW} {I}ndia.}
\newblock \emph{PLoS Neglected Tropical Diseases}, \textbf{7}(1), e1979.
\newblock \doi{10.1371/journal.pntd.0001979}.

\bibitem[{Shaman and Karspeck(2012)}]{Shaman2012}
Shaman J, Karspeck A (2012).
\newblock \enquote{Forecasting Seasonal Outbreaks of Influenza.}
\newblock \emph{Proceedings of the National Academy of Sciences of the United States of America}, \textbf{109}(50), 20425--20430.
\newblock \doi{10.1073/pnas.1208772109}.

\bibitem[{Shrestha \emph{et~al.}(2013)Shrestha, Foxman, {Weinberger}, Steiner, Viboud, and Rohani}]{Shrestha2013}
Shrestha S, Foxman B, {Weinberger} DM, Steiner C, Viboud C, Rohani P (2013).
\newblock \enquote{Identifying the Interaction between Influenza and Pneumococcal Pneumonia Using Incidence Data.}
\newblock \emph{Science Translational Medicine}, \textbf{5}(191), 191ra84.
\newblock \doi{10.1126/scitranslmed.3005982}.

\bibitem[{Shrestha \emph{et~al.}(2011)Shrestha, King, and Rohani}]{Shrestha2011}
Shrestha S, King AA, Rohani P (2011).
\newblock \enquote{Statistical Inference for Multi-Pathogen Systems.}
\newblock \emph{PLoS Computational Biology}, \textbf{7}, e1002135.
\newblock \doi{10.1371/journal.pcbi.1002135}.

\bibitem[{Sisson \emph{et~al.}(2007)Sisson, Fan, and Tanaka}]{Sisson2007}
Sisson S, Fan Y, Tanaka M (2007).
\newblock \enquote{Sequential {M}onte {C}arlo without Likelihoods.}
\newblock \emph{Proceedings of the National Academy of Sciences of the United States of America}, \textbf{104}(6), 1760--1765.
\newblock \doi{10.1073/pnas.0607208104}.

\bibitem[{Smith(1993)}]{Smith1993}
Smith A (1993).
\newblock \enquote{Estimating Nonlinear Time-Series Models Using Simulated Vector Autoregression.}
\newblock \emph{Journal of Applied Econometrics}, \textbf{8}(S1), S63--S84.
\newblock \doi{10.1002/jae.3950080506}.

\bibitem[{Toni \emph{et~al.}(2009)Toni, Welch, Strelkowa, Ipsen, and Stumpf}]{Toni2009}
Toni T, Welch D, Strelkowa N, Ipsen A, Stumpf M (2009).
\newblock \enquote{Approximate {B}ayesian Computation Scheme for Parameter Inference and Model Selection in Dynamical Systems.}
\newblock \emph{Journal of the Royal Society Interface}, \textbf{6}(31), 187--202.
\newblock \doi{10.1098/rsif.2008.0172}.

\bibitem[{Wan and Merwe(2000)}]{Wan2000}
Wan EA, Merwe R (2000).
\newblock \enquote{The Unscented {K}alman Filter for Nonlinear Estimation.}
\newblock In \emph{Adaptive Systems for Signal Processing, Communications, and Control}, pp. 153--158.
\newblock \doi{10.1109/asspcc.2000.882463}.

\bibitem[{Wood(2001)}]{Wood2001a}
Wood S (2001).
\newblock \enquote{Partially Specified Ecological Models.}
\newblock \emph{Ecological Monographs}, \textbf{71}, 1--25.
\newblock \doi{10.1890/0012-9615(2001)071[0001:psem]2.0.co;2}.

\bibitem[{Wood(2010)}]{Wood2010}
Wood S (2010).
\newblock \enquote{Statistical Inference for Noisy Nonlinear Ecological Dynamic Systems.}
\newblock \emph{Nature}, \textbf{466}(7310), 1102--1104.
\newblock \doi{10.1038/nature09319}.

\bibitem[{Xia and Tong(2011)}]{Xia2011}
Xia Y, Tong H (2011).
\newblock \enquote{Feature Matching in Time Series Modelling.}
\newblock \emph{Statistical Science}, \textbf{26}(1), 21--46.
\newblock \doi{10.1214/10-sts345}.

\bibitem[{Ypma(2014)}]{Ypma2014}
Ypma J (2014).
\newblock \emph{\pkg{nloptr}: \proglang{R} Interface to \pkg{NLopt}}.
\newblock \proglang{R}~package, version~1.0.0, \urlprefix\url{https://CRAN.R-project.org/package=nloptr}.

\end{thebibliography}


\end{document}

<<timing2,cache=FALSE>>=
bigtock <- Sys.time()
totalSweaveTime <- bigtock-bigtick
sysi <- Sys.info()
sess <- sessionInfo()
tfile <- "results/pompjss/timing.rda"

if (file.exists(tfile)) {
  load(tfile)
} else {
  save(totalSweaveTime,sysi,sess,file=tfile,compress='xz')
}

print(sysi)
print(sess)
print(mifTime)
print(pmcmcTime)
print(abcTime)
print(nlf.mif.time)
print(totalSweaveTime)
@
